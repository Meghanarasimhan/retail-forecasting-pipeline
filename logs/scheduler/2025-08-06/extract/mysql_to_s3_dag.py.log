[2025-08-06T01:48:44.775+0000] {processor.py:161} INFO - Started process (PID=164) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:48:44.777+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:48:44.787+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:48:44.785+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:48:44.802+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:48:44.797+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from my_dag_module import get_active_table_configs, extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'my_dag_module'
[2025-08-06T01:48:44.803+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:48:44.847+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.095 seconds
[2025-08-06T01:49:15.123+0000] {processor.py:161} INFO - Started process (PID=169) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:49:15.125+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:49:15.130+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:49:15.128+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:49:15.135+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:49:15.134+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from my_dag_module import get_active_table_configs, extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'my_dag_module'
[2025-08-06T01:49:15.136+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:49:15.159+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.049 seconds
[2025-08-06T01:49:45.469+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:49:45.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:49:45.476+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:49:45.475+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:49:45.487+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:49:45.485+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from my_dag_module import get_active_table_configs, extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'my_dag_module'
[2025-08-06T01:49:45.487+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:49:45.508+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.055 seconds
[2025-08-06T01:50:15.844+0000] {processor.py:161} INFO - Started process (PID=179) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:50:15.845+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:50:15.849+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:50:15.848+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:50:15.855+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:50:15.853+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from my_dag_module import get_active_table_configs, extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'my_dag_module'
[2025-08-06T01:50:15.856+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:50:15.880+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.050 seconds
[2025-08-06T01:50:46.226+0000] {processor.py:161} INFO - Started process (PID=184) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:50:46.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:50:46.231+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:50:46.231+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:50:46.235+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:50:46.234+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from my_dag_module import get_active_table_configs, extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'my_dag_module'
[2025-08-06T01:50:46.235+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:50:46.252+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.035 seconds
[2025-08-06T01:51:16.569+0000] {processor.py:161} INFO - Started process (PID=189) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:51:16.570+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:51:16.573+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:51:16.572+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:51:16.578+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:51:16.576+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from my_dag_module import get_active_table_configs, extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'my_dag_module'
[2025-08-06T01:51:16.578+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:51:16.592+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.031 seconds
[2025-08-06T01:51:46.926+0000] {processor.py:161} INFO - Started process (PID=194) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:51:46.927+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:51:46.930+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:51:46.929+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:51:46.937+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:51:46.935+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from my_dag_module import get_active_table_configs, extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'my_dag_module'
[2025-08-06T01:51:46.937+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:51:46.959+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.043 seconds
[2025-08-06T01:52:17.301+0000] {processor.py:161} INFO - Started process (PID=199) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:52:17.302+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:52:17.304+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:52:17.304+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:52:17.309+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:52:17.308+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from my_dag_module import get_active_table_configs, extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'my_dag_module'
[2025-08-06T01:52:17.309+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:52:17.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.034 seconds
[2025-08-06T01:52:47.687+0000] {processor.py:161} INFO - Started process (PID=204) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:52:47.688+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:52:47.690+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:52:47.690+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:52:47.698+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:52:47.697+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from my_dag_module import get_active_table_configs, extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'my_dag_module'
[2025-08-06T01:52:47.699+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:52:47.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.040 seconds
[2025-08-06T01:53:18.049+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:53:18.050+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:53:18.054+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:53:18.053+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:53:18.064+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:53:18.063+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from my_dag_module import get_active_table_configs, extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'my_dag_module'
[2025-08-06T01:53:18.065+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:53:18.079+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.039 seconds
[2025-08-06T01:53:44.314+0000] {processor.py:161} INFO - Started process (PID=214) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:53:44.316+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:53:44.320+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:53:44.319+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:53:44.325+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:53:44.324+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from my_dag_module import get_active_table_configs, extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'my_dag_module'
[2025-08-06T01:53:44.325+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:53:44.341+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.036 seconds
[2025-08-06T01:54:14.627+0000] {processor.py:161} INFO - Started process (PID=219) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:54:14.627+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:54:14.630+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:54:14.630+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:54:14.635+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:54:14.634+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from my_dag_module import get_active_table_configs, extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'my_dag_module'
[2025-08-06T01:54:14.636+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:54:14.656+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.037 seconds
[2025-08-06T01:54:44.987+0000] {processor.py:161} INFO - Started process (PID=224) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:54:44.989+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:54:44.993+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:54:44.993+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:54:44.998+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:54:44.997+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from my_dag_module import get_active_table_configs, extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'my_dag_module'
[2025-08-06T01:54:44.998+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:54:45.017+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.039 seconds
[2025-08-06T01:55:15.367+0000] {processor.py:161} INFO - Started process (PID=229) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:55:15.370+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:55:15.373+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:55:15.373+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:55:15.379+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:55:15.377+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from my_dag_module import get_active_table_configs, extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'my_dag_module'
[2025-08-06T01:55:15.379+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:55:15.398+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.044 seconds
[2025-08-06T01:55:45.747+0000] {processor.py:161} INFO - Started process (PID=234) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:55:45.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:55:45.750+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:55:45.750+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:55:45.758+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:55:45.757+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from my_dag_module import get_active_table_configs, extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'my_dag_module'
[2025-08-06T01:55:45.758+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:55:45.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.041 seconds
[2025-08-06T01:56:16.123+0000] {processor.py:161} INFO - Started process (PID=239) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:56:16.125+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:56:16.130+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:56:16.129+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:56:16.134+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:56:16.133+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from my_dag_module import get_active_table_configs, extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'my_dag_module'
[2025-08-06T01:56:16.134+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:56:16.151+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.037 seconds
[2025-08-06T01:56:46.516+0000] {processor.py:161} INFO - Started process (PID=244) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:56:46.517+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:56:46.521+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:56:46.520+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:56:46.525+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:56:46.524+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from my_dag_module import get_active_table_configs, extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'my_dag_module'
[2025-08-06T01:56:46.525+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:56:46.542+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.037 seconds
[2025-08-06T01:56:58.660+0000] {processor.py:161} INFO - Started process (PID=249) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:56:58.661+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:56:58.663+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:56:58.662+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:56:58.669+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:56:58.668+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T01:56:58.669+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:56:58.684+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.029 seconds
[2025-08-06T01:57:29.012+0000] {processor.py:161} INFO - Started process (PID=254) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:57:29.013+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:57:29.016+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:57:29.015+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:57:29.021+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:57:29.019+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T01:57:29.021+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:57:29.043+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.042 seconds
[2025-08-06T01:57:59.489+0000] {processor.py:161} INFO - Started process (PID=259) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:57:59.498+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:57:59.507+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:57:59.505+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:57:59.519+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:57:59.516+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T01:57:59.520+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:57:59.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.094 seconds
[2025-08-06T01:58:29.849+0000] {processor.py:161} INFO - Started process (PID=264) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:58:29.851+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:58:29.853+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:58:29.853+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:58:29.858+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:58:29.857+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T01:58:29.859+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:58:29.903+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.063 seconds
[2025-08-06T01:59:00.217+0000] {processor.py:161} INFO - Started process (PID=269) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:59:00.219+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:59:00.223+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:59:00.223+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:59:00.229+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:59:00.228+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T01:59:00.229+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:59:00.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.047 seconds
[2025-08-06T01:59:30.544+0000] {processor.py:161} INFO - Started process (PID=274) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:59:30.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T01:59:30.549+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:59:30.548+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:59:30.553+0000] {logging_mixin.py:188} INFO - [2025-08-06T01:59:30.552+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T01:59:30.554+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T01:59:30.581+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.050 seconds
[2025-08-06T02:00:00.923+0000] {processor.py:161} INFO - Started process (PID=279) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:00:00.925+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:00:00.929+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:00:00.928+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:00:00.934+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:00:00.933+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T02:00:00.934+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:00:00.961+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.052 seconds
[2025-08-06T02:00:31.294+0000] {processor.py:161} INFO - Started process (PID=284) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:00:31.295+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:00:31.298+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:00:31.297+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:00:31.306+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:00:31.305+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T02:00:31.306+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:00:31.325+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.045 seconds
[2025-08-06T02:01:01.687+0000] {processor.py:161} INFO - Started process (PID=289) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:01:01.688+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:01:01.690+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:01:01.690+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:01:01.695+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:01:01.694+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T02:01:01.696+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:01:01.716+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.037 seconds
[2025-08-06T02:01:32.053+0000] {processor.py:161} INFO - Started process (PID=294) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:01:32.054+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:01:32.057+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:01:32.056+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:01:32.062+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:01:32.060+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T02:01:32.062+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:01:32.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.037 seconds
[2025-08-06T02:02:02.481+0000] {processor.py:161} INFO - Started process (PID=299) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:02:02.483+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:02:02.486+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:02:02.485+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:02:02.491+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:02:02.490+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T02:02:02.491+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:02:02.514+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.044 seconds
[2025-08-06T02:02:32.886+0000] {processor.py:161} INFO - Started process (PID=304) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:02:32.889+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:02:32.893+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:02:32.893+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:02:32.899+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:02:32.897+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T02:02:32.899+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:02:32.923+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.057 seconds
[2025-08-06T02:03:03.257+0000] {processor.py:161} INFO - Started process (PID=309) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:03:03.258+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:03:03.260+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:03:03.260+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:03:03.265+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:03:03.264+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T02:03:03.265+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:03:03.286+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.036 seconds
[2025-08-06T02:03:33.615+0000] {processor.py:161} INFO - Started process (PID=314) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:03:33.617+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:03:33.621+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:03:33.621+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:03:33.626+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:03:33.625+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T02:03:33.626+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:03:33.646+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.038 seconds
[2025-08-06T02:04:04.037+0000] {processor.py:161} INFO - Started process (PID=319) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:04:04.039+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:04:04.043+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:04:04.043+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:04:04.049+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:04:04.048+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T02:04:04.050+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:04:04.077+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.048 seconds
[2025-08-06T02:04:34.418+0000] {processor.py:161} INFO - Started process (PID=324) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:04:34.420+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:04:34.424+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:04:34.424+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:04:34.428+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:04:34.427+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T02:04:34.428+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:04:34.448+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.037 seconds
[2025-08-06T02:05:04.834+0000] {processor.py:161} INFO - Started process (PID=329) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:05:04.835+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:05:04.839+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:05:04.839+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:05:04.849+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:05:04.844+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T02:05:04.849+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:05:04.873+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.053 seconds
[2025-08-06T02:05:35.284+0000] {processor.py:161} INFO - Started process (PID=334) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:05:35.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:05:35.289+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:05:35.289+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:05:35.294+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:05:35.293+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T02:05:35.295+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:05:35.320+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.046 seconds
[2025-08-06T02:06:05.688+0000] {processor.py:161} INFO - Started process (PID=339) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:06:05.689+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:06:05.693+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:06:05.692+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:06:05.700+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:06:05.697+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T02:06:05.700+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:06:05.725+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.051 seconds
[2025-08-06T02:06:36.094+0000] {processor.py:161} INFO - Started process (PID=344) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:06:36.095+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:06:36.098+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:06:36.097+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:06:36.102+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:06:36.101+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T02:06:36.102+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:06:36.126+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.041 seconds
[2025-08-06T02:07:06.449+0000] {processor.py:161} INFO - Started process (PID=349) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:07:06.450+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:07:06.453+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:07:06.452+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:07:06.460+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:07:06.457+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T02:07:06.460+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:07:06.482+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.042 seconds
[2025-08-06T02:07:36.751+0000] {processor.py:161} INFO - Started process (PID=354) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:07:36.752+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:07:36.755+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:07:36.754+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:07:36.759+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:07:36.758+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T02:07:36.760+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:07:36.778+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.036 seconds
[2025-08-06T02:08:07.108+0000] {processor.py:161} INFO - Started process (PID=359) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:08:07.111+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:08:07.114+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:08:07.114+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:08:07.119+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:08:07.118+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T02:08:07.119+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:08:07.140+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.041 seconds
[2025-08-06T02:08:37.483+0000] {processor.py:161} INFO - Started process (PID=364) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:08:37.485+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:08:37.487+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:08:37.487+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:08:37.491+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:08:37.490+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T02:08:37.492+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:08:37.516+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.040 seconds
[2025-08-06T02:09:07.953+0000] {processor.py:161} INFO - Started process (PID=369) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:09:07.956+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:09:07.962+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:09:07.961+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:09:07.968+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:09:07.966+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T02:09:07.968+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:09:07.992+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.054 seconds
[2025-08-06T02:09:38.383+0000] {processor.py:161} INFO - Started process (PID=374) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:09:38.385+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:09:38.388+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:09:38.387+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:09:38.392+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:09:38.391+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 4, in <module>
    from helpers.extract_load_functions import extract_from_mysql, upload_to_s3
ModuleNotFoundError: No module named 'helpers'
[2025-08-06T02:09:38.393+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:09:38.412+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.037 seconds
[2025-08-06T02:10:08.741+0000] {processor.py:161} INFO - Started process (PID=379) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:10:08.742+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:10:08.745+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:10:08.744+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:10:11.208+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:10:11.207+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:10:11.234+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:10:11.233+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 15, in <module>
    configs = get_active_table_configs()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/helpers/metadata_extract.py", line 6, in get_active_table_configs
    result = mysql_hook.get_records(query)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 283, in get_records
    return self.run(sql=sql, parameters=parameters, handler=fetch_all_handler)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 411, in run
    with closing(self.get_conn()) as conn:
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/mysql/hooks/mysql.py", line 195, in get_conn
    return MySQLdb.connect(**conn_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/MySQLdb/__init__.py", line 121, in Connect
    return Connection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/MySQLdb/connections.py", line 195, in __init__
    super().__init__(*args, **kwargs2)
MySQLdb.OperationalError: (2002, "Can't connect to server on '127.0.0.1' (115)")
[2025-08-06T02:10:11.235+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:10:11.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 2.509 seconds
[2025-08-06T02:10:41.671+0000] {processor.py:161} INFO - Started process (PID=385) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:10:41.673+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:10:41.676+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:10:41.675+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:10:42.158+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:10:42.158+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:10:42.165+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:10:42.162+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 15, in <module>
    configs = get_active_table_configs()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/helpers/metadata_extract.py", line 6, in get_active_table_configs
    result = mysql_hook.get_records(query)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 283, in get_records
    return self.run(sql=sql, parameters=parameters, handler=fetch_all_handler)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 411, in run
    with closing(self.get_conn()) as conn:
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/mysql/hooks/mysql.py", line 195, in get_conn
    return MySQLdb.connect(**conn_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/MySQLdb/__init__.py", line 121, in Connect
    return Connection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/MySQLdb/connections.py", line 195, in __init__
    super().__init__(*args, **kwargs2)
MySQLdb.OperationalError: (2002, "Can't connect to server on '127.0.0.1' (115)")
[2025-08-06T02:10:42.165+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:10:42.171+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.512 seconds
[2025-08-06T02:11:12.416+0000] {processor.py:161} INFO - Started process (PID=391) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:11:12.418+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:11:12.422+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:11:12.422+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:11:12.819+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:11:12.819+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:11:12.823+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:11:12.822+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 15, in <module>
    configs = get_active_table_configs()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/helpers/metadata_extract.py", line 6, in get_active_table_configs
    result = mysql_hook.get_records(query)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 283, in get_records
    return self.run(sql=sql, parameters=parameters, handler=fetch_all_handler)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 411, in run
    with closing(self.get_conn()) as conn:
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/mysql/hooks/mysql.py", line 195, in get_conn
    return MySQLdb.connect(**conn_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/MySQLdb/__init__.py", line 121, in Connect
    return Connection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/MySQLdb/connections.py", line 195, in __init__
    super().__init__(*args, **kwargs2)
MySQLdb.OperationalError: (2002, "Can't connect to server on '127.0.0.1' (115)")
[2025-08-06T02:11:12.824+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:11:12.827+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.427 seconds
[2025-08-06T02:11:43.187+0000] {processor.py:161} INFO - Started process (PID=397) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:11:43.189+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:11:43.194+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:11:43.193+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:11:43.614+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:11:43.614+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:11:43.620+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:11:43.618+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 15, in <module>
    configs = get_active_table_configs()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/helpers/metadata_extract.py", line 6, in get_active_table_configs
    result = mysql_hook.get_records(query)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 283, in get_records
    return self.run(sql=sql, parameters=parameters, handler=fetch_all_handler)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 411, in run
    with closing(self.get_conn()) as conn:
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/mysql/hooks/mysql.py", line 195, in get_conn
    return MySQLdb.connect(**conn_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/MySQLdb/__init__.py", line 121, in Connect
    return Connection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/MySQLdb/connections.py", line 195, in __init__
    super().__init__(*args, **kwargs2)
MySQLdb.OperationalError: (2002, "Can't connect to server on '127.0.0.1' (115)")
[2025-08-06T02:11:43.621+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:11:43.628+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.457 seconds
[2025-08-06T02:12:14.008+0000] {processor.py:161} INFO - Started process (PID=403) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:12:14.010+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:12:14.013+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:12:14.013+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:12:15.225+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:12:15.225+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:12:15.231+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:12:15.228+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 15, in <module>
    configs = get_active_table_configs()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/helpers/metadata_extract.py", line 6, in get_active_table_configs
    result = mysql_hook.get_records(query)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 283, in get_records
    return self.run(sql=sql, parameters=parameters, handler=fetch_all_handler)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 411, in run
    with closing(self.get_conn()) as conn:
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/mysql/hooks/mysql.py", line 195, in get_conn
    return MySQLdb.connect(**conn_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/MySQLdb/__init__.py", line 121, in Connect
    return Connection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/MySQLdb/connections.py", line 195, in __init__
    super().__init__(*args, **kwargs2)
MySQLdb.OperationalError: (2002, "Can't connect to server on '127.0.0.1' (115)")
[2025-08-06T02:12:15.231+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:12:15.236+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 1.243 seconds
[2025-08-06T02:12:45.375+0000] {processor.py:161} INFO - Started process (PID=409) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:12:45.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:12:45.380+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:12:45.379+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:12:45.829+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:12:45.828+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:12:45.833+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:12:45.832+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 15, in <module>
    configs = get_active_table_configs()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/helpers/metadata_extract.py", line 6, in get_active_table_configs
    result = mysql_hook.get_records(query)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 283, in get_records
    return self.run(sql=sql, parameters=parameters, handler=fetch_all_handler)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 411, in run
    with closing(self.get_conn()) as conn:
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/mysql/hooks/mysql.py", line 195, in get_conn
    return MySQLdb.connect(**conn_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/MySQLdb/__init__.py", line 121, in Connect
    return Connection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/MySQLdb/connections.py", line 195, in __init__
    super().__init__(*args, **kwargs2)
MySQLdb.OperationalError: (2002, "Can't connect to server on '127.0.0.1' (115)")
[2025-08-06T02:12:45.834+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:12:45.837+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.472 seconds
[2025-08-06T02:13:16.185+0000] {processor.py:161} INFO - Started process (PID=415) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:13:16.187+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:13:16.189+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:13:16.189+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:13:16.593+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:13:16.593+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:13:16.597+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:13:16.596+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 15, in <module>
    configs = get_active_table_configs()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/helpers/metadata_extract.py", line 6, in get_active_table_configs
    result = mysql_hook.get_records(query)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 283, in get_records
    return self.run(sql=sql, parameters=parameters, handler=fetch_all_handler)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 411, in run
    with closing(self.get_conn()) as conn:
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/mysql/hooks/mysql.py", line 195, in get_conn
    return MySQLdb.connect(**conn_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/MySQLdb/__init__.py", line 121, in Connect
    return Connection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/MySQLdb/connections.py", line 195, in __init__
    super().__init__(*args, **kwargs2)
MySQLdb.OperationalError: (2002, "Can't connect to server on '127.0.0.1' (115)")
[2025-08-06T02:13:16.598+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:13:16.601+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.426 seconds
[2025-08-06T02:13:46.900+0000] {processor.py:161} INFO - Started process (PID=421) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:13:46.901+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:13:46.904+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:13:46.903+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:13:47.304+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:13:47.303+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:13:47.309+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:13:47.307+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 15, in <module>
    configs = get_active_table_configs()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/helpers/metadata_extract.py", line 6, in get_active_table_configs
    result = mysql_hook.get_records(query)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 283, in get_records
    return self.run(sql=sql, parameters=parameters, handler=fetch_all_handler)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 411, in run
    with closing(self.get_conn()) as conn:
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/mysql/hooks/mysql.py", line 195, in get_conn
    return MySQLdb.connect(**conn_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/MySQLdb/__init__.py", line 121, in Connect
    return Connection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/MySQLdb/connections.py", line 195, in __init__
    super().__init__(*args, **kwargs2)
MySQLdb.OperationalError: (2002, "Can't connect to server on '127.0.0.1' (115)")
[2025-08-06T02:13:47.309+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:13:47.312+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.429 seconds
[2025-08-06T02:14:17.710+0000] {processor.py:161} INFO - Started process (PID=427) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:14:17.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:14:17.724+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:14:17.724+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:14:18.657+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:14:18.657+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:14:18.665+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:14:18.662+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/extract/mysql_to_s3_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/extract/mysql_to_s3_dag.py", line 15, in <module>
    configs = get_active_table_configs()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/helpers/metadata_extract.py", line 6, in get_active_table_configs
    result = mysql_hook.get_records(query)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 283, in get_records
    return self.run(sql=sql, parameters=parameters, handler=fetch_all_handler)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 411, in run
    with closing(self.get_conn()) as conn:
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/mysql/hooks/mysql.py", line 195, in get_conn
    return MySQLdb.connect(**conn_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/MySQLdb/__init__.py", line 121, in Connect
    return Connection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/MySQLdb/connections.py", line 195, in __init__
    super().__init__(*args, **kwargs2)
MySQLdb.OperationalError: (2002, "Can't connect to server on '127.0.0.1' (115)")
[2025-08-06T02:14:18.666+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:14:18.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.991 seconds
[2025-08-06T02:14:49.087+0000] {processor.py:161} INFO - Started process (PID=433) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:14:49.088+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:14:49.092+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:14:49.092+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:14:49.532+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:14:49.531+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:14:49.639+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:14:49.639+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:14:49.668+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:14:49.667+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:14:49.695+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:14:49.878+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:14:49.878+0000] {override.py:1829} INFO - Created Permission View: can edit on DAG:mysql_to_s3_metadata_dag
[2025-08-06T02:14:49.881+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:14:49.881+0000] {override.py:1829} INFO - Created Permission View: can read on DAG:mysql_to_s3_metadata_dag
[2025-08-06T02:14:49.883+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:14:49.883+0000] {override.py:1829} INFO - Created Permission View: can delete on DAG:mysql_to_s3_metadata_dag
[2025-08-06T02:14:49.883+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:14:49.883+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:14:49.889+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:14:49.889+0000] {dag.py:3118} INFO - Creating ORM DAG for mysql_to_s3_metadata_dag
[2025-08-06T02:14:49.890+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:14:49.890+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:14:49.902+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.821 seconds
[2025-08-06T02:15:20.319+0000] {processor.py:161} INFO - Started process (PID=439) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:15:20.322+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:15:20.326+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:15:20.326+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:15:21.138+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:15:21.138+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:15:21.172+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:15:21.172+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:15:21.176+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:15:21.176+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:15:21.185+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:15:21.203+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:15:21.203+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:15:21.212+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:15:21.212+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:15:21.225+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.947 seconds
[2025-08-06T02:15:51.716+0000] {processor.py:161} INFO - Started process (PID=480) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:15:51.718+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:15:51.720+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:15:51.720+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:15:52.143+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:15:52.142+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:15:52.161+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:15:52.161+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:15:52.162+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:15:52.162+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:15:52.168+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:15:52.175+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:15:52.175+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:15:52.179+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:15:52.179+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:15:52.186+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.480 seconds
[2025-08-06T02:16:22.486+0000] {processor.py:161} INFO - Started process (PID=486) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:16:22.488+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:16:22.490+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:16:22.490+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:16:22.901+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:16:22.901+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:16:22.911+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:16:22.911+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:16:22.912+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:16:22.912+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:16:22.914+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:16:22.920+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:16:22.920+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:16:22.925+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:16:22.925+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:16:22.931+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.460 seconds
[2025-08-06T02:16:53.270+0000] {processor.py:161} INFO - Started process (PID=492) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:16:53.272+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:16:53.274+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:16:53.274+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:16:53.690+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:16:53.690+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:16:53.700+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:16:53.700+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:16:53.702+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:16:53.701+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:16:53.704+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:16:53.710+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:16:53.710+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:16:53.714+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:16:53.714+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:16:53.721+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.459 seconds
[2025-08-06T02:17:24.066+0000] {processor.py:161} INFO - Started process (PID=498) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:17:24.067+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:17:24.069+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:17:24.069+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:17:24.523+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:17:24.523+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:17:24.597+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:17:24.597+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:17:24.621+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:17:24.621+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:17:24.628+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:17:24.637+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:17:24.637+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:17:24.644+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:17:24.644+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:17:24.653+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.597 seconds
[2025-08-06T02:17:54.952+0000] {processor.py:161} INFO - Started process (PID=504) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:17:54.956+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:17:54.959+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:17:54.959+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:17:55.393+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:17:55.393+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:17:55.411+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:17:55.411+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:17:55.412+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:17:55.412+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:17:55.415+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:17:55.421+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:17:55.421+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:17:55.426+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:17:55.426+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:17:55.432+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.491 seconds
[2025-08-06T02:18:25.749+0000] {processor.py:161} INFO - Started process (PID=510) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:18:25.752+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:18:25.755+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:18:25.755+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:18:26.192+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:18:26.192+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:18:26.202+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:18:26.201+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:18:26.203+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:18:26.203+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:18:26.205+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:18:26.212+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:18:26.212+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:18:26.216+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:18:26.216+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:18:26.222+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.483 seconds
[2025-08-06T02:18:56.604+0000] {processor.py:161} INFO - Started process (PID=516) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:18:56.606+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:18:56.609+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:18:56.608+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:18:57.109+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:18:57.108+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:18:57.127+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:18:57.127+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:18:57.129+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:18:57.128+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:18:57.132+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:18:57.139+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:18:57.139+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:18:57.144+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:18:57.144+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:18:57.153+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.567 seconds
[2025-08-06T02:19:27.446+0000] {processor.py:161} INFO - Started process (PID=522) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:19:27.452+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:19:27.454+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:19:27.454+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:19:27.957+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:19:27.957+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:19:27.971+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:19:27.971+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:19:27.982+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:19:27.982+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:19:27.985+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:19:27.992+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:19:27.992+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:19:27.996+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:19:27.996+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:19:28.003+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.568 seconds
[2025-08-06T02:19:58.386+0000] {processor.py:161} INFO - Started process (PID=528) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:19:58.387+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:19:58.390+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:19:58.390+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:19:58.849+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:19:58.849+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:19:58.860+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:19:58.860+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:19:58.861+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:19:58.861+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:19:58.864+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:19:58.870+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:19:58.870+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:19:58.875+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:19:58.875+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:19:58.882+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.509 seconds
[2025-08-06T02:20:29.150+0000] {processor.py:161} INFO - Started process (PID=534) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:20:29.151+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:20:29.159+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:20:29.159+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:20:29.649+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:20:29.649+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:20:29.664+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:20:29.664+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:20:29.665+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:20:29.665+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:20:29.669+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:20:29.674+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:20:29.674+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:20:29.679+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:20:29.679+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:20:29.686+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.548 seconds
[2025-08-06T02:21:00.054+0000] {processor.py:161} INFO - Started process (PID=540) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:21:00.056+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:21:00.064+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:21:00.063+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:21:00.499+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:21:00.499+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:21:00.514+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:21:00.514+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:21:00.515+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:21:00.515+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:21:00.519+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:21:00.530+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:21:00.530+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:21:00.538+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:21:00.537+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:21:00.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.506 seconds
[2025-08-06T02:21:30.771+0000] {processor.py:161} INFO - Started process (PID=546) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:21:30.773+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:21:30.776+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:21:30.776+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:21:31.215+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:21:31.215+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:21:31.225+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:21:31.225+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:21:31.227+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:21:31.227+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:21:31.230+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:21:31.239+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:21:31.239+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:21:31.243+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:21:31.243+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:21:31.250+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.490 seconds
[2025-08-06T02:22:01.572+0000] {processor.py:161} INFO - Started process (PID=552) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:22:01.574+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:22:01.577+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:22:01.576+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:22:02.033+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:22:02.033+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:22:02.046+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:22:02.046+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:22:02.047+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:22:02.047+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:22:02.050+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:22:02.060+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:22:02.060+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:22:02.064+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:22:02.064+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:22:02.071+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.511 seconds
[2025-08-06T02:22:32.450+0000] {processor.py:161} INFO - Started process (PID=561) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:22:32.452+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:22:32.456+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:22:32.455+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:22:33.070+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:22:33.070+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:22:33.086+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:22:33.086+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:22:33.087+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:22:33.087+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:22:33.091+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:22:33.098+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:22:33.098+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:22:33.102+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:22:33.102+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:22:33.110+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.679 seconds
[2025-08-06T02:23:03.469+0000] {processor.py:161} INFO - Started process (PID=567) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:23:03.473+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:23:03.478+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:23:03.477+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:23:03.914+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:23:03.914+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:23:03.924+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:23:03.924+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:23:03.926+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:23:03.926+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:23:03.930+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:23:03.937+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:23:03.937+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:23:03.941+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:23:03.941+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:23:03.948+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.498 seconds
[2025-08-06T02:23:34.310+0000] {processor.py:161} INFO - Started process (PID=573) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:23:34.312+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:23:34.317+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:23:34.316+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:23:34.688+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:23:34.688+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:23:34.695+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:23:34.695+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:23:34.696+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:23:34.696+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:23:34.698+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:23:34.705+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:23:34.705+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:23:34.710+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:23:34.710+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:23:34.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.427 seconds
[2025-08-06T02:24:05.039+0000] {processor.py:161} INFO - Started process (PID=579) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:24:05.040+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:24:05.045+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:24:05.043+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:24:05.531+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:24:05.531+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:24:05.543+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:24:05.543+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:24:05.544+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:24:05.544+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:24:05.547+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:24:05.553+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:24:05.553+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:24:05.558+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:24:05.558+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:24:05.565+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.540 seconds
[2025-08-06T02:24:35.905+0000] {processor.py:161} INFO - Started process (PID=585) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:24:35.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:24:35.910+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:24:35.909+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:24:36.380+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:24:36.380+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:24:36.394+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:24:36.394+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:24:36.395+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:24:36.395+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:24:36.399+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:24:36.409+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:24:36.409+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:24:36.414+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:24:36.414+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:24:36.421+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.527 seconds
[2025-08-06T02:25:06.785+0000] {processor.py:161} INFO - Started process (PID=591) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:25:06.788+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:25:06.793+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:25:06.793+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:25:07.309+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:25:07.309+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:25:07.348+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:25:07.347+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:25:07.349+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:25:07.349+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:25:07.353+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:25:07.415+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:25:07.415+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:25:07.420+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:25:07.420+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:25:07.429+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.651 seconds
[2025-08-06T02:25:37.813+0000] {processor.py:161} INFO - Started process (PID=597) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:25:37.815+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:25:37.820+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:25:37.819+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:25:38.297+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:25:38.296+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:25:38.310+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:25:38.309+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:25:38.311+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:25:38.310+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:25:38.314+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:25:38.321+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:25:38.321+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:25:38.326+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:25:38.326+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:25:38.336+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.540 seconds
[2025-08-06T02:26:08.502+0000] {processor.py:161} INFO - Started process (PID=603) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:26:08.504+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:26:08.506+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:26:08.506+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:26:09.013+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:26:09.012+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:26:09.028+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:26:09.028+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:26:09.029+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:26:09.029+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:26:09.032+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:26:09.039+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:26:09.039+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:26:09.044+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:26:09.044+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:26:09.052+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.564 seconds
[2025-08-06T02:26:39.446+0000] {processor.py:161} INFO - Started process (PID=609) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:26:39.447+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:26:39.449+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:26:39.449+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:26:39.844+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:26:39.844+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:26:39.861+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:26:39.861+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:26:39.862+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:26:39.862+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:26:39.865+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:26:39.872+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:26:39.872+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:26:39.877+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:26:39.877+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:26:39.884+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.450 seconds
[2025-08-06T02:27:10.250+0000] {processor.py:161} INFO - Started process (PID=615) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:27:10.251+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:27:10.254+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:27:10.253+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:27:10.711+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:27:10.710+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:27:10.722+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:27:10.722+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:27:10.723+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:27:10.723+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:27:10.727+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:27:10.733+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:27:10.733+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:27:10.739+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:27:10.739+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:27:10.746+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.514 seconds
[2025-08-06T02:27:41.087+0000] {processor.py:161} INFO - Started process (PID=621) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:27:41.089+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:27:41.093+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:27:41.093+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:27:41.508+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:27:41.508+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:27:41.520+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:27:41.520+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:27:41.521+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:27:41.521+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:27:41.524+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:27:41.531+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:27:41.531+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:27:41.536+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:27:41.536+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:27:41.542+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.465 seconds
[2025-08-06T02:28:11.907+0000] {processor.py:161} INFO - Started process (PID=627) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:28:11.912+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:28:11.916+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:28:11.915+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:28:12.313+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:28:12.313+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:28:12.325+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:28:12.325+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:28:12.326+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:28:12.326+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:28:12.329+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:28:12.336+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:28:12.336+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:28:12.341+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:28:12.341+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:28:12.348+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.454 seconds
[2025-08-06T02:28:42.824+0000] {processor.py:161} INFO - Started process (PID=673) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:28:42.825+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:28:42.829+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:28:42.828+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:28:43.307+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:28:43.307+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:28:43.325+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:28:43.325+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:28:43.326+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:28:43.326+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:28:43.330+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:28:43.339+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:28:43.339+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:28:43.343+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:28:43.343+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:28:43.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.540 seconds
[2025-08-06T02:29:13.682+0000] {processor.py:161} INFO - Started process (PID=679) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:29:13.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:29:13.689+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:29:13.688+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:29:14.111+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:29:14.111+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:29:14.125+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:29:14.125+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:29:14.126+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:29:14.126+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:29:14.129+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:29:14.136+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:29:14.135+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:29:14.142+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:29:14.142+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:29:14.148+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.479 seconds
[2025-08-06T02:29:44.594+0000] {processor.py:161} INFO - Started process (PID=685) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:29:44.597+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:29:44.600+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:29:44.600+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:29:44.985+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:29:44.985+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:29:45.000+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:29:45.000+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:29:45.001+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:29:45.001+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:29:45.004+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:29:45.011+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:29:45.011+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:29:45.016+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:29:45.016+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:29:45.024+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.451 seconds
[2025-08-06T02:30:15.390+0000] {processor.py:161} INFO - Started process (PID=691) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:30:15.391+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:30:15.395+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:30:15.394+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:30:15.837+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:30:15.836+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:30:15.854+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:30:15.854+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:30:15.855+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:30:15.855+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:30:15.858+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:30:15.865+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:30:15.865+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:30:15.870+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:30:15.870+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:30:15.877+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.499 seconds
[2025-08-06T02:30:46.253+0000] {processor.py:161} INFO - Started process (PID=697) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:30:46.254+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:30:46.257+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:30:46.257+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:30:46.667+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:30:46.667+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:30:46.684+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:30:46.684+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:30:46.685+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:30:46.685+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:30:46.690+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:30:46.699+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:30:46.699+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:30:46.706+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:30:46.706+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:30:46.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.475 seconds
[2025-08-06T02:31:17.117+0000] {processor.py:161} INFO - Started process (PID=703) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:31:17.119+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:31:17.122+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:31:17.122+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:31:17.548+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:31:17.548+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:31:17.620+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:31:17.620+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:31:17.670+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:31:17.670+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:31:17.675+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:31:17.685+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:31:17.685+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:31:17.694+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:31:17.693+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:31:17.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.599 seconds
[2025-08-06T02:31:47.852+0000] {processor.py:161} INFO - Started process (PID=709) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:31:47.853+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:31:47.857+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:31:47.857+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:31:48.268+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:31:48.268+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:31:48.283+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:31:48.283+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:31:48.285+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:31:48.285+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:31:48.288+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:31:48.295+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:31:48.295+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:31:48.303+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:31:48.303+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:31:48.311+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.469 seconds
[2025-08-06T02:32:18.408+0000] {processor.py:161} INFO - Started process (PID=715) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:32:18.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:32:18.414+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:32:18.413+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:32:18.814+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:32:18.814+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:32:18.826+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:32:18.826+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:32:18.827+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:32:18.827+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:32:18.831+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:32:18.838+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:32:18.838+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:32:18.843+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:32:18.843+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:32:18.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.456 seconds
[2025-08-06T02:32:49.028+0000] {processor.py:161} INFO - Started process (PID=721) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:32:49.030+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:32:49.039+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:32:49.039+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:32:49.492+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:32:49.492+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:32:49.519+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:32:49.519+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:32:49.521+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:32:49.521+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:32:49.524+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:32:49.533+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:32:49.533+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:32:49.538+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:32:49.538+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:32:49.546+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.534 seconds
[2025-08-06T02:33:19.851+0000] {processor.py:161} INFO - Started process (PID=727) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:33:19.853+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:33:19.856+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:33:19.856+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:33:20.262+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:33:20.261+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:33:20.277+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:33:20.277+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:33:20.278+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:33:20.278+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:33:20.281+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:33:20.288+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:33:20.288+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:33:20.294+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:33:20.294+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:33:20.303+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.469 seconds
[2025-08-06T02:33:50.638+0000] {processor.py:161} INFO - Started process (PID=733) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:33:50.639+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:33:50.642+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:33:50.642+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:33:50.976+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:33:50.976+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:33:50.987+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:33:50.987+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:33:50.988+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:33:50.988+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:33:50.990+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:33:50.997+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:33:50.997+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:33:51.001+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:33:51.001+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:33:51.007+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.381 seconds
[2025-08-06T02:34:21.125+0000] {processor.py:161} INFO - Started process (PID=819) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:34:21.127+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:34:21.130+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:34:21.130+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:34:21.546+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:34:21.546+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:34:21.560+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:34:21.560+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:34:21.561+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:34:21.561+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:34:21.564+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:34:21.575+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:34:21.575+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:34:21.579+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:34:21.579+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:34:21.585+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.475 seconds
[2025-08-06T02:34:51.948+0000] {processor.py:161} INFO - Started process (PID=825) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:34:51.950+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:34:51.954+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:34:51.953+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:34:52.374+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:34:52.374+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:34:52.387+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:34:52.387+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:34:52.388+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:34:52.388+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:34:52.391+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:34:52.397+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:34:52.397+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:34:52.402+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:34:52.402+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:34:52.408+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.476 seconds
[2025-08-06T02:35:22.796+0000] {processor.py:161} INFO - Started process (PID=831) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:35:22.797+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:35:22.801+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:35:22.800+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:35:23.238+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:35:23.238+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:35:23.251+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:35:23.251+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:35:23.252+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:35:23.252+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:35:23.255+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:35:23.262+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:35:23.262+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:35:23.267+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:35:23.266+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:35:23.273+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.489 seconds
[2025-08-06T02:35:53.660+0000] {processor.py:161} INFO - Started process (PID=837) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:35:53.662+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:35:53.665+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:35:53.664+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:35:54.095+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:35:54.095+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:35:54.108+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:35:54.107+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:35:54.109+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:35:54.108+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:35:54.111+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:35:54.117+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:35:54.117+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:35:54.124+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:35:54.124+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:35:54.130+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.479 seconds
[2025-08-06T02:36:24.458+0000] {processor.py:161} INFO - Started process (PID=843) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:36:24.459+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:36:24.463+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:36:24.463+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:36:24.869+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:36:24.869+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:36:24.879+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:36:24.879+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:36:24.880+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:36:24.880+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:36:24.883+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:36:24.889+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:36:24.889+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:36:24.894+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:36:24.894+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:36:24.900+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.461 seconds
[2025-08-06T02:36:55.239+0000] {processor.py:161} INFO - Started process (PID=849) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:36:55.241+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:36:55.250+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:36:55.248+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:36:55.651+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:36:55.651+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:36:55.661+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:36:55.660+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:36:55.662+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:36:55.662+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:36:55.664+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:36:55.671+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:36:55.671+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:36:55.675+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:36:55.675+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:36:55.681+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.454 seconds
[2025-08-06T02:37:25.994+0000] {processor.py:161} INFO - Started process (PID=855) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:37:25.997+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:37:26.001+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:37:26.000+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:37:26.415+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:37:26.415+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:37:26.423+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:37:26.423+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:37:26.424+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:37:26.424+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:37:26.427+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:37:26.433+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:37:26.433+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:37:26.437+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:37:26.437+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:37:26.444+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.463 seconds
[2025-08-06T02:37:56.851+0000] {processor.py:161} INFO - Started process (PID=861) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:37:56.854+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:37:56.858+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:37:56.857+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:37:57.266+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:37:57.265+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:37:57.278+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:37:57.278+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:37:57.279+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:37:57.279+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:37:57.282+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:37:57.288+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:37:57.288+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:37:57.292+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:37:57.292+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:37:57.298+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.463 seconds
[2025-08-06T02:38:27.624+0000] {processor.py:161} INFO - Started process (PID=867) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:38:27.626+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:38:27.629+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:38:27.629+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:38:28.054+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:38:28.053+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:38:28.064+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:38:28.064+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:38:28.066+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:38:28.065+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:38:28.068+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:38:28.075+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:38:28.075+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:38:28.079+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:38:28.079+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:38:28.085+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.472 seconds
[2025-08-06T02:38:58.467+0000] {processor.py:161} INFO - Started process (PID=873) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:38:58.469+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:38:58.472+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:38:58.472+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:38:58.891+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:38:58.891+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:38:58.900+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:38:58.900+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:38:58.901+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:38:58.901+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:38:58.905+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:38:58.911+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:38:58.911+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:38:58.916+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:38:58.916+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:38:58.923+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.479 seconds
[2025-08-06T02:39:29.247+0000] {processor.py:161} INFO - Started process (PID=879) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:39:29.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:39:29.252+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:39:29.251+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:39:29.664+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:39:29.664+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:39:29.672+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:39:29.672+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:39:29.673+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:39:29.673+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:39:29.677+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:39:29.684+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:39:29.684+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:39:29.690+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:39:29.690+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:39:29.696+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.474 seconds
[2025-08-06T02:40:00.079+0000] {processor.py:161} INFO - Started process (PID=885) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:40:00.081+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:40:00.085+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:40:00.084+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:40:00.504+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:40:00.504+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:40:00.513+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:40:00.513+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:40:00.514+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:40:00.514+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:40:00.517+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:40:00.523+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:40:00.523+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:40:00.528+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:40:00.528+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:40:00.536+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.472 seconds
[2025-08-06T02:40:30.875+0000] {processor.py:161} INFO - Started process (PID=891) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:40:30.876+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:40:30.884+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:40:30.882+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:40:31.298+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:40:31.298+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:40:31.308+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:40:31.308+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:40:31.309+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:40:31.309+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:40:31.312+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:40:31.318+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:40:31.318+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:40:31.327+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:40:31.327+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:40:31.334+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.479 seconds
[2025-08-06T02:41:01.716+0000] {processor.py:161} INFO - Started process (PID=897) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:41:01.720+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:41:01.724+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:41:01.723+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:41:02.145+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:41:02.144+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:41:02.156+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:41:02.156+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:41:02.157+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:41:02.157+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:41:02.160+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:41:02.166+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:41:02.166+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:41:02.170+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:41:02.170+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:41:02.177+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.477 seconds
[2025-08-06T02:41:32.502+0000] {processor.py:161} INFO - Started process (PID=903) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:41:32.505+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:41:32.511+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:41:32.510+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:41:32.934+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:41:32.934+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:41:32.943+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:41:32.943+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:41:32.944+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:41:32.944+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:41:32.947+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:41:32.953+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:41:32.953+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:41:32.957+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:41:32.957+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:41:32.966+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.481 seconds
[2025-08-06T02:42:03.347+0000] {processor.py:161} INFO - Started process (PID=909) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:42:03.354+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:42:03.357+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:42:03.356+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:42:03.819+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:42:03.819+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:42:03.904+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:42:03.904+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:42:03.923+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:42:03.923+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:42:03.928+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:42:03.938+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:42:03.938+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:42:03.945+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:42:03.945+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:42:03.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.622 seconds
[2025-08-06T02:42:34.306+0000] {processor.py:161} INFO - Started process (PID=915) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:42:34.308+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:42:34.312+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:42:34.311+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:42:34.667+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:42:34.666+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:42:34.676+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:42:34.676+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:42:34.678+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:42:34.678+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:42:34.680+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:42:34.687+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:42:34.686+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:42:34.691+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:42:34.691+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:42:34.698+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.403 seconds
[2025-08-06T02:43:05.009+0000] {processor.py:161} INFO - Started process (PID=921) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:43:05.010+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:43:05.012+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:43:05.012+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:43:05.257+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:43:05.257+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:43:05.262+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:43:05.262+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:43:05.263+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:43:05.263+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:43:05.265+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:43:05.271+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:43:05.271+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:43:05.274+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:43:05.274+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:43:05.280+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.278 seconds
[2025-08-06T02:43:35.335+0000] {processor.py:161} INFO - Started process (PID=927) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:43:35.336+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:43:35.338+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:43:35.338+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:43:35.576+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:43:35.576+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:43:35.583+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:43:35.582+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:43:35.583+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:43:35.583+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:43:35.585+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:43:35.591+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:43:35.591+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:43:35.594+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:43:35.594+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:43:35.600+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.270 seconds
[2025-08-06T02:44:05.799+0000] {processor.py:161} INFO - Started process (PID=933) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:44:05.800+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:44:05.803+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:44:05.803+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:44:06.111+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:44:06.111+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:44:06.119+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:44:06.119+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:44:06.120+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:44:06.120+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:44:06.122+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:44:06.128+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:44:06.128+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:44:06.132+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:44:06.132+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:44:06.138+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.350 seconds
[2025-08-06T02:44:36.276+0000] {processor.py:161} INFO - Started process (PID=939) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:44:36.277+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:44:36.278+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:44:36.278+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:44:36.534+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:44:36.534+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:44:36.540+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:44:36.540+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:44:36.541+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:44:36.541+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:44:36.544+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:44:36.549+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:44:36.549+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:44:36.553+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:44:36.553+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:44:36.558+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.286 seconds
[2025-08-06T02:45:06.951+0000] {processor.py:161} INFO - Started process (PID=945) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:45:06.952+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:45:06.956+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:45:06.955+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:45:07.338+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:45:07.338+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:45:07.347+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:45:07.347+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:45:07.348+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:45:07.348+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:45:07.354+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:45:07.360+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:45:07.360+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:45:07.365+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:45:07.365+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:45:07.371+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.432 seconds
[2025-08-06T02:45:37.764+0000] {processor.py:161} INFO - Started process (PID=951) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:45:37.765+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:45:37.769+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:45:37.769+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:45:38.081+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:45:38.081+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:45:38.087+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:45:38.087+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:45:38.088+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:45:38.088+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:45:38.090+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:45:38.096+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:45:38.096+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:45:38.101+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:45:38.101+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:45:38.107+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.353 seconds
[2025-08-06T02:46:08.468+0000] {processor.py:161} INFO - Started process (PID=957) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:46:08.469+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:46:08.471+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:46:08.470+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:46:08.722+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:46:08.722+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:46:08.728+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:46:08.728+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:46:08.729+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:46:08.729+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:46:08.731+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:46:08.737+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:46:08.737+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:46:08.741+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:46:08.741+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:46:08.747+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.288 seconds
[2025-08-06T02:46:38.889+0000] {processor.py:161} INFO - Started process (PID=963) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:46:38.894+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:46:38.898+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:46:38.898+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:46:39.302+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:46:39.302+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:46:39.313+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:46:39.312+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:46:39.314+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:46:39.313+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:46:39.316+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:46:39.322+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:46:39.322+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:46:39.327+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:46:39.327+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:46:39.335+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.458 seconds
[2025-08-06T02:47:09.599+0000] {processor.py:161} INFO - Started process (PID=969) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:47:09.601+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:47:09.606+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:47:09.605+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:47:10.031+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:47:10.031+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:47:10.039+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:47:10.038+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:47:10.039+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:47:10.039+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:47:10.042+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:47:10.048+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:47:10.048+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:47:10.053+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:47:10.053+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:47:10.059+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.482 seconds
[2025-08-06T02:47:40.436+0000] {processor.py:161} INFO - Started process (PID=975) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:47:40.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:47:40.439+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:47:40.438+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:47:40.681+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:47:40.681+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:47:40.686+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:47:40.686+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:47:40.687+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:47:40.687+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:47:40.689+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:47:40.695+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:47:40.695+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:47:40.699+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:47:40.699+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:47:40.705+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.275 seconds
[2025-08-06T02:48:10.792+0000] {processor.py:161} INFO - Started process (PID=981) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:48:10.794+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:48:10.798+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:48:10.797+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:48:11.204+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:48:11.204+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:48:11.217+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:48:11.217+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:48:11.218+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:48:11.218+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:48:11.222+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:48:11.231+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:48:11.231+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:48:11.237+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:48:11.237+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:48:11.245+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.465 seconds
[2025-08-06T02:48:41.510+0000] {processor.py:161} INFO - Started process (PID=987) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:48:41.511+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:48:41.514+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:48:41.514+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:48:41.917+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:48:41.916+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:48:41.923+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:48:41.923+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:48:41.924+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:48:41.924+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:48:41.926+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:48:41.932+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:48:41.932+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:48:41.937+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:48:41.937+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:48:41.944+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.450 seconds
[2025-08-06T02:49:12.025+0000] {processor.py:161} INFO - Started process (PID=993) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:49:12.027+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:49:12.035+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:49:12.033+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:49:12.464+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:49:12.463+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:49:12.472+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:49:12.472+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:49:12.473+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:49:12.473+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:49:12.476+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:49:12.483+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:49:12.483+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:49:12.487+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:49:12.487+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:49:12.494+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.486 seconds
[2025-08-06T02:49:42.698+0000] {processor.py:161} INFO - Started process (PID=999) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:49:42.700+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:49:42.704+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:49:42.703+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:49:43.139+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:49:43.139+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:49:43.147+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:49:43.147+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:49:43.148+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:49:43.148+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:49:43.151+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:49:43.157+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:49:43.157+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:49:43.161+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:49:43.161+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:49:43.169+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.494 seconds
[2025-08-06T02:50:13.495+0000] {processor.py:161} INFO - Started process (PID=1005) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:50:13.496+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:50:13.499+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:50:13.498+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:50:13.897+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:50:13.897+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:50:13.904+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:50:13.904+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:50:13.906+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:50:13.906+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:50:13.911+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:50:13.917+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:50:13.917+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:50:13.922+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:50:13.922+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:50:13.928+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.449 seconds
[2025-08-06T02:50:44.321+0000] {processor.py:161} INFO - Started process (PID=1011) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:50:44.323+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:50:44.326+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:50:44.326+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:50:44.750+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:50:44.750+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:50:44.761+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:50:44.761+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:50:44.765+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:50:44.765+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:50:44.769+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:50:44.775+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:50:44.775+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:50:44.779+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:50:44.779+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:50:44.785+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.483 seconds
[2025-08-06T02:51:15.188+0000] {processor.py:161} INFO - Started process (PID=1017) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:51:15.189+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:51:15.192+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:51:15.191+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:51:15.619+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:51:15.618+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:51:15.630+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:51:15.630+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:51:15.632+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:51:15.632+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:51:15.635+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:51:15.641+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:51:15.641+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:51:15.646+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:51:15.645+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:51:15.652+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.473 seconds
[2025-08-06T02:51:46.045+0000] {processor.py:161} INFO - Started process (PID=1023) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:51:46.046+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:51:46.051+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:51:46.050+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:51:46.390+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:51:46.390+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:51:46.395+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:51:46.395+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:51:46.396+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:51:46.396+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:51:46.398+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:51:46.404+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:51:46.404+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:51:46.410+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:51:46.410+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:51:46.418+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.387 seconds
[2025-08-06T02:52:16.884+0000] {processor.py:161} INFO - Started process (PID=1029) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:52:16.886+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:52:16.892+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:52:16.889+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:52:17.344+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:52:17.344+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:52:17.352+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:52:17.352+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:52:17.356+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:52:17.356+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:52:17.359+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:52:17.365+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:52:17.365+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:52:17.369+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:52:17.369+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:52:17.376+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.516 seconds
[2025-08-06T02:52:47.830+0000] {processor.py:161} INFO - Started process (PID=1035) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:52:47.832+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:52:47.836+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:52:47.836+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:52:48.240+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:52:48.240+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:52:48.249+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:52:48.248+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:52:48.250+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:52:48.249+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:52:48.252+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:52:48.258+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:52:48.258+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:52:48.268+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:52:48.268+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:52:48.274+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.465 seconds
[2025-08-06T02:53:18.688+0000] {processor.py:161} INFO - Started process (PID=1041) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:53:18.690+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:53:18.693+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:53:18.693+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:53:19.108+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:53:19.107+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:53:19.116+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:53:19.116+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:53:19.117+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:53:19.117+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:53:19.124+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:53:19.130+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:53:19.130+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:53:19.135+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:53:19.135+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:53:19.141+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.466 seconds
[2025-08-06T02:53:49.530+0000] {processor.py:161} INFO - Started process (PID=1047) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:53:49.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:53:49.537+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:53:49.537+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:53:49.958+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:53:49.958+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:53:49.971+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:53:49.971+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:53:49.972+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:53:49.972+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:53:49.975+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:53:49.981+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:53:49.981+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:53:49.985+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:53:49.985+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:53:49.991+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.484 seconds
[2025-08-06T02:54:20.416+0000] {processor.py:161} INFO - Started process (PID=1053) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:54:20.419+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:54:20.422+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:54:20.421+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:54:20.851+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:54:20.851+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:54:20.858+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:54:20.858+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:54:20.859+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:54:20.859+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:54:20.862+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:54:20.873+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:54:20.873+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:54:20.878+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:54:20.878+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:54:20.885+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.490 seconds
[2025-08-06T02:54:51.224+0000] {processor.py:161} INFO - Started process (PID=1059) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:54:51.227+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:54:51.232+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:54:51.231+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:54:51.650+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:54:51.650+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:54:51.660+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:54:51.660+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:54:51.661+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:54:51.661+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:54:51.664+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:54:51.670+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:54:51.670+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:54:51.675+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:54:51.675+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:54:51.685+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.474 seconds
[2025-08-06T02:55:22.127+0000] {processor.py:161} INFO - Started process (PID=1065) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:55:22.129+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:55:22.133+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:55:22.132+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:55:22.544+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:55:22.544+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:55:22.554+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:55:22.554+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:55:22.556+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:55:22.556+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:55:22.559+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:55:22.566+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:55:22.566+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:55:22.570+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:55:22.570+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:55:22.577+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.470 seconds
[2025-08-06T02:55:53.036+0000] {processor.py:161} INFO - Started process (PID=1071) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:55:53.037+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:55:53.046+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:55:53.045+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:55:53.458+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:55:53.458+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:55:53.467+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:55:53.467+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:55:53.468+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:55:53.468+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:55:53.470+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:55:53.477+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:55:53.477+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:55:53.484+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:55:53.484+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:55:53.491+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.473 seconds
[2025-08-06T02:56:23.780+0000] {processor.py:161} INFO - Started process (PID=1077) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:56:23.782+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:56:23.793+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:56:23.792+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:56:24.226+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:56:24.225+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:56:24.233+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:56:24.233+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:56:24.234+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:56:24.234+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:56:24.237+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:56:24.243+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:56:24.243+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:56:24.247+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:56:24.247+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:56:24.254+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.486 seconds
[2025-08-06T02:56:54.682+0000] {processor.py:161} INFO - Started process (PID=1083) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:56:54.684+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:56:54.689+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:56:54.688+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:56:55.137+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:56:55.137+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:56:55.145+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:56:55.144+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:56:55.151+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:56:55.151+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:56:55.154+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:56:55.160+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:56:55.160+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:56:55.164+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:56:55.164+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:56:55.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.505 seconds
[2025-08-06T02:57:25.625+0000] {processor.py:161} INFO - Started process (PID=1089) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:57:25.627+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:57:25.631+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:57:25.630+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:57:26.084+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:57:26.084+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:57:26.098+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:57:26.098+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:57:26.100+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:57:26.100+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:57:26.103+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:57:26.109+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:57:26.109+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:57:26.114+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:57:26.114+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:57:26.124+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.519 seconds
[2025-08-06T02:57:56.490+0000] {processor.py:161} INFO - Started process (PID=1095) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:57:56.492+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:57:56.495+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:57:56.495+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:57:56.893+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:57:56.893+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:57:56.903+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:57:56.903+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:57:56.904+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:57:56.904+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:57:56.907+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:57:56.913+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:57:56.913+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:57:56.918+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:57:56.918+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:57:56.925+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.457 seconds
[2025-08-06T02:58:27.410+0000] {processor.py:161} INFO - Started process (PID=1101) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:58:27.413+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:58:27.420+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:58:27.419+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:58:27.826+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:58:27.826+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:58:27.841+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:58:27.841+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:58:27.842+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:58:27.842+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:58:27.845+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:58:27.851+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:58:27.851+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:58:27.856+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:58:27.856+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:58:27.862+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.476 seconds
[2025-08-06T02:58:58.217+0000] {processor.py:161} INFO - Started process (PID=1107) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:58:58.221+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:58:58.225+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:58:58.224+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:58:58.665+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:58:58.664+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:58:58.674+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:58:58.673+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:58:58.675+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:58:58.674+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:58:58.677+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:58:58.683+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:58:58.683+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:58:58.688+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:58:58.688+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:58:58.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.502 seconds
[2025-08-06T02:59:29.103+0000] {processor.py:161} INFO - Started process (PID=1113) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:59:29.107+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T02:59:29.112+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:59:29.111+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:59:29.534+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:59:29.534+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T02:59:29.545+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:59:29.545+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T02:59:29.547+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:59:29.546+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T02:59:29.549+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T02:59:29.556+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:59:29.556+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T02:59:29.560+0000] {logging_mixin.py:188} INFO - [2025-08-06T02:59:29.560+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T02:59:29.567+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.479 seconds
[2025-08-06T03:00:00.093+0000] {processor.py:161} INFO - Started process (PID=1119) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:00:00.095+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:00:00.101+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:00:00.099+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:00:00.495+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:00:00.495+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:00:00.505+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:00:00.504+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:00:00.506+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:00:00.506+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:00:00.509+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:00:00.515+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:00:00.515+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:00:00.520+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:00:00.520+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:00:00.526+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.446 seconds
[2025-08-06T03:00:30.884+0000] {processor.py:161} INFO - Started process (PID=1125) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:00:30.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:00:30.888+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:00:30.888+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:00:31.308+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:00:31.308+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:00:31.319+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:00:31.319+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:00:31.320+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:00:31.320+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:00:31.323+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:00:31.329+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:00:31.329+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:00:31.334+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:00:31.334+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:00:31.341+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.473 seconds
[2025-08-06T03:01:01.774+0000] {processor.py:161} INFO - Started process (PID=1131) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:01:01.775+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:01:01.778+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:01:01.777+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:01:02.172+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:01:02.172+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:01:02.181+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:01:02.181+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:01:02.182+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:01:02.182+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:01:02.186+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:01:02.192+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:01:02.192+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:01:02.197+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:01:02.197+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:01:02.204+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.442 seconds
[2025-08-06T03:01:32.620+0000] {processor.py:161} INFO - Started process (PID=1137) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:01:32.622+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:01:32.624+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:01:32.624+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:01:33.035+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:01:33.034+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:01:33.046+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:01:33.046+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:01:33.047+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:01:33.047+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:01:33.050+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:01:33.056+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:01:33.056+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:01:33.061+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:01:33.061+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:01:33.067+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.458 seconds
[2025-08-06T03:02:03.485+0000] {processor.py:161} INFO - Started process (PID=1143) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:02:03.487+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:02:03.492+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:02:03.491+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:02:03.902+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:02:03.902+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:02:03.913+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:02:03.913+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:02:03.914+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:02:03.914+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:02:03.917+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:02:03.924+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:02:03.924+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:02:03.928+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:02:03.928+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:02:03.935+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.467 seconds
[2025-08-06T03:02:34.351+0000] {processor.py:161} INFO - Started process (PID=1149) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:02:34.353+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:02:34.357+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:02:34.356+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:02:34.804+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:02:34.804+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:02:34.817+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:02:34.817+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:02:34.818+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:02:34.818+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:02:34.821+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:02:34.830+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:02:34.830+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:02:34.835+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:02:34.834+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:02:34.841+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.501 seconds
[2025-08-06T03:03:05.215+0000] {processor.py:161} INFO - Started process (PID=1155) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:03:05.216+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:03:05.219+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:03:05.219+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:03:05.621+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:03:05.621+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:03:05.632+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:03:05.631+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:03:05.633+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:03:05.633+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:03:05.636+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:03:05.642+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:03:05.642+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:03:05.646+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:03:05.646+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:03:05.657+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.460 seconds
[2025-08-06T03:03:36.033+0000] {processor.py:161} INFO - Started process (PID=1161) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:03:36.034+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:03:36.038+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:03:36.037+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:03:36.346+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:03:36.346+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:03:36.352+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:03:36.352+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:03:36.353+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:03:36.353+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:03:36.355+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:03:36.360+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:03:36.360+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:03:36.364+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:03:36.364+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:03:36.370+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.348 seconds
[2025-08-06T03:04:06.786+0000] {processor.py:161} INFO - Started process (PID=1167) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:04:06.787+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:04:06.790+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:04:06.790+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:04:07.059+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:04:07.059+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:04:07.071+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:04:07.071+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:04:07.072+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:04:07.072+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:04:07.075+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:04:07.081+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:04:07.081+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:04:07.086+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:04:07.086+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:04:07.093+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.318 seconds
[2025-08-06T03:04:37.183+0000] {processor.py:161} INFO - Started process (PID=1173) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:04:37.185+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:04:37.188+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:04:37.188+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:04:37.606+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:04:37.606+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:04:37.619+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:04:37.619+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:04:37.620+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:04:37.620+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:04:37.623+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:04:37.631+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:04:37.631+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:04:37.637+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:04:37.637+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:04:37.645+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.473 seconds
[2025-08-06T03:05:07.832+0000] {processor.py:161} INFO - Started process (PID=1179) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:05:07.834+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:05:07.839+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:05:07.838+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:05:08.247+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:05:08.247+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:05:08.258+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:05:08.258+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:05:08.259+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:05:08.259+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:05:08.262+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:05:08.268+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:05:08.268+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:05:08.272+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:05:08.272+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:05:08.279+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.463 seconds
[2025-08-06T03:05:38.614+0000] {processor.py:161} INFO - Started process (PID=1185) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:05:38.615+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:05:38.619+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:05:38.618+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:05:38.870+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:05:38.870+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:05:38.877+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:05:38.877+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:05:38.878+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:05:38.877+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:05:38.880+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:05:38.886+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:05:38.886+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:05:38.890+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:05:38.890+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:05:38.896+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.292 seconds
[2025-08-06T03:06:08.990+0000] {processor.py:161} INFO - Started process (PID=1191) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:06:08.992+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:06:08.995+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:06:08.994+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:06:09.430+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:06:09.430+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:06:09.437+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:06:09.437+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:06:09.438+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:06:09.438+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:06:09.443+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:06:09.449+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:06:09.449+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:06:09.453+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:06:09.453+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:06:09.460+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.488 seconds
[2025-08-06T03:06:39.711+0000] {processor.py:161} INFO - Started process (PID=1197) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:06:39.715+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:06:39.719+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:06:39.718+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:06:40.121+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:06:40.121+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:06:40.129+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:06:40.129+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:06:40.130+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:06:40.130+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:06:40.133+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:06:40.142+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:06:40.142+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:06:40.148+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:06:40.148+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:06:40.154+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.460 seconds
[2025-08-06T03:07:10.593+0000] {processor.py:161} INFO - Started process (PID=1203) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:07:10.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:07:10.599+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:07:10.598+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:07:11.009+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:07:11.009+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:07:11.018+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:07:11.018+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:07:11.023+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:07:11.023+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:07:11.026+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:07:11.032+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:07:11.032+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:07:11.037+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:07:11.037+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:07:11.043+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.469 seconds
[2025-08-06T03:07:41.523+0000] {processor.py:161} INFO - Started process (PID=1209) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:07:41.524+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:07:41.527+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:07:41.527+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:07:41.786+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:07:41.786+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:07:41.792+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:07:41.791+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:07:41.792+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:07:41.792+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:07:41.795+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:07:41.801+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:07:41.801+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:07:41.805+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:07:41.805+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:07:41.811+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.299 seconds
[2025-08-06T03:08:11.946+0000] {processor.py:161} INFO - Started process (PID=1215) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:08:11.948+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:08:11.952+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:08:11.952+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:08:12.353+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:08:12.353+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:08:12.361+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:08:12.361+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:08:12.362+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:08:12.362+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:08:12.365+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:08:12.371+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:08:12.371+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:08:12.375+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:08:12.375+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:08:12.382+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.455 seconds
[2025-08-06T03:08:42.530+0000] {processor.py:161} INFO - Started process (PID=1221) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:08:42.532+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:08:42.535+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:08:42.534+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:08:42.940+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:08:42.940+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:08:42.949+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:08:42.949+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:08:42.952+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:08:42.952+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:08:42.954+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:08:42.961+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:08:42.961+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:08:42.965+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:08:42.965+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:08:42.972+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.454 seconds
[2025-08-06T03:09:13.121+0000] {processor.py:161} INFO - Started process (PID=1227) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:09:13.124+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:09:13.135+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:09:13.134+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:09:13.583+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:09:13.583+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:09:13.596+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:09:13.596+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:09:13.597+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:09:13.597+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:09:13.600+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:09:13.606+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:09:13.606+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:09:13.610+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:09:13.610+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:09:13.617+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.510 seconds
[2025-08-06T03:09:43.759+0000] {processor.py:161} INFO - Started process (PID=1233) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:09:43.760+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:09:43.766+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:09:43.766+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:09:44.198+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:09:44.197+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:09:44.206+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:09:44.205+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:09:44.206+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:09:44.206+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:09:44.209+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:09:44.219+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:09:44.219+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:09:44.224+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:09:44.224+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:09:44.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.490 seconds
[2025-08-06T03:10:14.378+0000] {processor.py:161} INFO - Started process (PID=1239) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:10:14.379+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:10:14.385+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:10:14.384+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:10:14.805+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:10:14.805+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:10:14.815+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:10:14.815+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:10:14.816+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:10:14.816+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:10:14.819+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:10:14.825+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:10:14.825+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:10:14.830+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:10:14.830+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:10:14.836+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.473 seconds
[2025-08-06T03:10:45.238+0000] {processor.py:161} INFO - Started process (PID=1245) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:10:45.240+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:10:45.247+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:10:45.243+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:10:45.650+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:10:45.650+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:10:45.658+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:10:45.658+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:10:45.659+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:10:45.659+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:10:45.663+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:10:45.670+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:10:45.670+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:10:45.674+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:10:45.674+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:10:45.681+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.465 seconds
[2025-08-06T03:11:16.061+0000] {processor.py:161} INFO - Started process (PID=1251) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:11:16.063+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:11:16.066+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:11:16.066+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:11:16.476+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:11:16.476+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:11:16.485+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:11:16.485+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:11:16.486+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:11:16.486+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:11:16.489+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:11:16.495+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:11:16.495+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:11:16.499+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:11:16.499+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:11:16.506+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.460 seconds
[2025-08-06T03:11:46.979+0000] {processor.py:161} INFO - Started process (PID=1257) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:11:46.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:11:46.991+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:11:46.990+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:11:47.416+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:11:47.416+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:11:47.424+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:11:47.424+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:11:47.425+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:11:47.425+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:11:47.427+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:11:47.440+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:11:47.440+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:11:47.444+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:11:47.444+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:11:47.451+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.486 seconds
[2025-08-06T03:12:17.827+0000] {processor.py:161} INFO - Started process (PID=1263) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:12:17.829+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:12:17.833+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:12:17.832+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:12:18.254+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:12:18.254+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:12:18.263+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:12:18.263+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:12:18.264+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:12:18.264+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:12:18.267+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:12:18.273+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:12:18.273+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:12:18.277+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:12:18.277+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:12:18.283+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.476 seconds
[2025-08-06T03:12:48.628+0000] {processor.py:161} INFO - Started process (PID=1269) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:12:48.630+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:12:48.635+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:12:48.634+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:12:49.050+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:12:49.050+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:12:49.063+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:12:49.062+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:12:49.064+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:12:49.063+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:12:49.066+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:12:49.073+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:12:49.073+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:12:49.078+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:12:49.078+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:12:49.084+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.479 seconds
[2025-08-06T03:13:19.519+0000] {processor.py:161} INFO - Started process (PID=1275) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:13:19.520+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:13:19.525+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:13:19.524+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:13:19.930+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:13:19.930+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:13:19.940+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:13:19.940+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:13:19.941+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:13:19.941+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:13:19.944+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:13:19.950+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:13:19.950+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:13:19.955+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:13:19.955+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:13:19.961+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.457 seconds
[2025-08-06T03:13:50.281+0000] {processor.py:161} INFO - Started process (PID=1281) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:13:50.282+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:13:50.287+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:13:50.286+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:13:50.752+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:13:50.752+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:13:50.762+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:13:50.762+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:13:50.763+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:13:50.763+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:13:50.766+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:13:50.773+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:13:50.773+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:13:50.779+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:13:50.779+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:13:50.787+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.522 seconds
[2025-08-06T03:14:21.225+0000] {processor.py:161} INFO - Started process (PID=1287) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:14:21.226+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:14:21.231+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:14:21.231+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:14:21.666+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:14:21.666+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:14:21.676+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:14:21.676+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:14:21.677+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:14:21.677+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:14:21.679+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:14:21.686+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:14:21.685+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:14:21.690+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:14:21.690+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:14:21.696+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.482 seconds
[2025-08-06T03:14:52.101+0000] {processor.py:161} INFO - Started process (PID=1293) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:14:52.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:14:52.115+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:14:52.113+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:14:52.547+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:14:52.547+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:14:52.557+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:14:52.556+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:14:52.558+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:14:52.558+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:14:52.564+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:14:52.572+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:14:52.572+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:14:52.576+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:14:52.576+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:14:52.582+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.501 seconds
[2025-08-06T03:15:22.999+0000] {processor.py:161} INFO - Started process (PID=1299) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:15:23.001+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:15:23.006+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:15:23.005+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:15:23.434+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:15:23.434+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:15:23.442+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:15:23.442+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:15:23.444+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:15:23.443+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:15:23.446+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:15:23.452+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:15:23.452+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:15:23.456+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:15:23.456+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:15:23.462+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.480 seconds
[2025-08-06T03:15:53.901+0000] {processor.py:161} INFO - Started process (PID=1305) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:15:53.902+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:15:53.908+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:15:53.907+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:15:54.321+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:15:54.321+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:15:54.333+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:15:54.333+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:15:54.334+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:15:54.334+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:15:54.337+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:15:54.347+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:15:54.347+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:15:54.359+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:15:54.359+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:15:54.367+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.476 seconds
[2025-08-06T03:16:24.768+0000] {processor.py:161} INFO - Started process (PID=1311) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:16:24.770+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:16:24.775+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:16:24.774+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:16:25.204+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:16:25.204+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:16:25.212+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:16:25.212+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:16:25.213+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:16:25.213+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:16:25.218+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:16:25.225+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:16:25.225+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:16:25.230+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:16:25.230+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:16:25.236+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.488 seconds
[2025-08-06T03:16:55.594+0000] {processor.py:161} INFO - Started process (PID=1317) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:16:55.596+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:16:55.605+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:16:55.604+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:16:56.026+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:16:56.026+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:16:56.036+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:16:56.036+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:16:56.037+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:16:56.037+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:16:56.040+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:16:56.047+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:16:56.047+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:16:56.051+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:16:56.051+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:16:56.057+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.482 seconds
[2025-08-06T03:17:26.496+0000] {processor.py:161} INFO - Started process (PID=1323) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:17:26.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:17:26.508+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:17:26.506+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:17:26.945+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:17:26.945+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:17:26.956+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:17:26.956+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:17:26.957+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:17:26.957+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:17:26.963+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:17:26.969+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:17:26.969+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:17:26.974+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:17:26.974+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:17:26.982+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.502 seconds
[2025-08-06T03:17:57.475+0000] {processor.py:161} INFO - Started process (PID=1329) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:17:57.477+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:17:57.480+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:17:57.480+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:17:57.885+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:17:57.885+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:17:57.897+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:17:57.897+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:17:57.898+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:17:57.898+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:17:57.901+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:17:57.907+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:17:57.907+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:17:57.911+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:17:57.911+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:17:57.918+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.457 seconds
[2025-08-06T03:18:28.344+0000] {processor.py:161} INFO - Started process (PID=1335) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:18:28.347+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:18:28.351+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:18:28.350+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:18:28.785+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:18:28.785+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:18:28.794+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:18:28.794+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:18:28.795+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:18:28.795+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:18:28.800+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:18:28.806+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:18:28.806+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:18:28.810+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:18:28.810+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:18:28.816+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.493 seconds
[2025-08-06T03:18:59.307+0000] {processor.py:161} INFO - Started process (PID=1341) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:18:59.309+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:18:59.315+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:18:59.314+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:18:59.718+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:18:59.718+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:18:59.727+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:18:59.727+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:18:59.728+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:18:59.728+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:18:59.731+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:18:59.737+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:18:59.737+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:18:59.742+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:18:59.742+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:18:59.748+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.463 seconds
[2025-08-06T03:19:30.078+0000] {processor.py:161} INFO - Started process (PID=1347) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:19:30.081+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:19:30.088+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:19:30.087+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:19:30.511+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:19:30.510+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:19:30.526+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:19:30.526+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:19:30.528+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:19:30.527+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:19:30.530+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:19:30.537+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:19:30.536+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:19:30.541+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:19:30.541+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:19:30.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.490 seconds
[2025-08-06T03:20:00.952+0000] {processor.py:161} INFO - Started process (PID=1353) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:20:00.953+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:20:00.958+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:20:00.957+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:20:01.379+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:20:01.379+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:20:01.390+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:20:01.390+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:20:01.391+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:20:01.391+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:20:01.394+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:20:01.400+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:20:01.400+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:20:01.405+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:20:01.405+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:20:01.411+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.475 seconds
[2025-08-06T03:20:31.826+0000] {processor.py:161} INFO - Started process (PID=1359) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:20:31.827+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:20:31.831+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:20:31.831+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:20:32.217+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:20:32.216+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:20:32.229+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:20:32.229+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:20:32.230+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:20:32.230+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:20:32.233+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:20:32.241+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:20:32.241+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:20:32.246+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:20:32.246+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:20:32.252+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.439 seconds
[2025-08-06T03:21:02.593+0000] {processor.py:161} INFO - Started process (PID=1365) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:21:02.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:21:02.597+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:21:02.597+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:21:03.014+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:21:03.013+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:21:03.022+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:21:03.022+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:21:03.023+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:21:03.023+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:21:03.026+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:21:03.034+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:21:03.034+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:21:03.038+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:21:03.038+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:21:03.045+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.464 seconds
[2025-08-06T03:21:33.488+0000] {processor.py:161} INFO - Started process (PID=1371) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:21:33.489+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:21:33.494+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:21:33.494+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:21:33.924+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:21:33.924+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:21:33.934+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:21:33.934+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:21:33.935+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:21:33.935+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:21:33.938+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:21:33.944+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:21:33.944+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:21:33.949+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:21:33.949+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:21:33.955+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.486 seconds
[2025-08-06T03:22:04.343+0000] {processor.py:161} INFO - Started process (PID=1377) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:22:04.344+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:22:04.349+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:22:04.348+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:22:04.756+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:22:04.755+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:22:04.765+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:22:04.765+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:22:04.766+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:22:04.766+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:22:04.769+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:22:04.776+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:22:04.776+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:22:04.781+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:22:04.781+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:22:04.788+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.459 seconds
[2025-08-06T03:22:35.193+0000] {processor.py:161} INFO - Started process (PID=1383) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:22:35.194+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:22:35.197+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:22:35.197+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:22:35.620+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:22:35.620+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:22:35.630+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:22:35.630+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:22:35.631+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:22:35.631+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:22:35.634+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:22:35.640+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:22:35.640+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:22:35.647+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:22:35.647+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:22:35.654+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.472 seconds
[2025-08-06T03:23:06.104+0000] {processor.py:161} INFO - Started process (PID=1389) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:23:06.106+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:23:06.112+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:23:06.112+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:23:06.563+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:23:06.563+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:23:06.572+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:23:06.572+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:23:06.572+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:23:06.572+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:23:06.575+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:23:06.582+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:23:06.582+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:23:06.588+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:23:06.588+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:23:06.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.506 seconds
[2025-08-06T03:23:36.872+0000] {processor.py:161} INFO - Started process (PID=1395) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:23:36.873+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:23:36.877+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:23:36.876+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:23:37.287+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:23:37.287+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:23:37.298+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:23:37.298+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:23:37.304+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:23:37.304+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:23:37.308+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:23:37.315+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:23:37.315+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:23:37.319+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:23:37.319+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:23:37.325+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.464 seconds
[2025-08-06T03:24:07.793+0000] {processor.py:161} INFO - Started process (PID=1401) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:24:07.796+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:24:07.800+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:24:07.799+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:24:08.237+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:24:08.236+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:24:08.250+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:24:08.250+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:24:08.252+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:24:08.251+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:24:08.254+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:24:08.260+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:24:08.260+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:24:08.265+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:24:08.265+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:24:08.272+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.495 seconds
[2025-08-06T03:24:38.655+0000] {processor.py:161} INFO - Started process (PID=1407) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:24:38.657+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:24:38.664+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:24:38.664+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:24:39.124+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:24:39.124+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:24:39.136+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:24:39.136+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:24:39.138+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:24:39.137+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:24:39.140+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:24:39.148+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:24:39.148+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:24:39.152+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:24:39.152+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:24:39.159+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.525 seconds
[2025-08-06T03:25:09.552+0000] {processor.py:161} INFO - Started process (PID=1413) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:25:09.554+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:25:09.557+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:25:09.557+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:25:09.960+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:25:09.960+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:25:09.973+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:25:09.973+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:25:09.974+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:25:09.974+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:25:09.977+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:25:09.983+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:25:09.983+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:25:09.988+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:25:09.988+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:25:09.994+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.454 seconds
[2025-08-06T03:25:40.375+0000] {processor.py:161} INFO - Started process (PID=1419) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:25:40.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T03:25:40.381+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:25:40.380+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:25:40.802+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:25:40.802+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T03:25:40.813+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:25:40.813+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T03:25:40.814+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:25:40.814+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T03:25:40.817+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T03:25:40.823+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:25:40.823+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T03:25:40.828+0000] {logging_mixin.py:188} INFO - [2025-08-06T03:25:40.828+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T03:25:40.835+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.477 seconds
[2025-08-06T15:34:18.940+0000] {processor.py:161} INFO - Started process (PID=164) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:34:18.943+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:34:18.945+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:34:18.945+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:34:19.440+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:34:19.440+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:34:19.457+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:34:19.456+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:34:19.458+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:34:19.458+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:34:19.465+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:34:19.467+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:34:19.467+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:34:19.472+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:34:19.472+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:34:19.478+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.542 seconds
[2025-08-06T15:34:49.869+0000] {processor.py:161} INFO - Started process (PID=170) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:34:49.870+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:34:49.873+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:34:49.872+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:34:50.270+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:34:50.270+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:34:50.352+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:34:50.352+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:34:50.377+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:34:50.377+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:34:50.381+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:34:50.438+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:34:50.438+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:34:50.442+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:34:50.441+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:34:50.450+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.591 seconds
[2025-08-06T15:35:20.779+0000] {processor.py:161} INFO - Started process (PID=176) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:35:20.781+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:35:20.786+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:35:20.785+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:35:21.159+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:35:21.159+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:35:21.171+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:35:21.171+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:35:21.173+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:35:21.173+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:35:21.176+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:35:21.182+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:35:21.182+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:35:21.186+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:35:21.186+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:35:21.193+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.429 seconds
[2025-08-06T15:35:51.543+0000] {processor.py:161} INFO - Started process (PID=182) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:35:51.544+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:35:51.547+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:35:51.547+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:35:51.901+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:35:51.901+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:35:51.910+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:35:51.910+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:35:51.911+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:35:51.911+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:35:51.914+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:35:51.920+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:35:51.920+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:35:51.924+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:35:51.924+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:35:51.934+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.413 seconds
[2025-08-06T15:36:22.297+0000] {processor.py:161} INFO - Started process (PID=188) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:36:22.299+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:36:22.303+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:36:22.302+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:36:22.673+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:36:22.673+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:36:22.701+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:36:22.701+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:36:22.704+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:36:22.703+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:36:22.706+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:36:22.713+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:36:22.712+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:36:22.717+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:36:22.717+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:36:22.723+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.443 seconds
[2025-08-06T15:36:53.081+0000] {processor.py:161} INFO - Started process (PID=194) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:36:53.083+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:36:53.087+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:36:53.086+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:36:53.474+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:36:53.474+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:36:53.490+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:36:53.490+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:36:53.492+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:36:53.491+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:36:53.497+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:36:53.504+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:36:53.504+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:36:53.509+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:36:53.509+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:36:53.516+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.444 seconds
[2025-08-06T15:37:23.853+0000] {processor.py:161} INFO - Started process (PID=200) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:37:23.855+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:37:23.857+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:37:23.857+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:37:24.219+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:37:24.219+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:37:24.232+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:37:24.232+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:37:24.234+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:37:24.234+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:37:24.237+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:37:24.243+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:37:24.243+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:37:24.247+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:37:24.247+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:37:24.254+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.412 seconds
[2025-08-06T15:37:54.607+0000] {processor.py:161} INFO - Started process (PID=206) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:37:54.610+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:37:54.612+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:37:54.611+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:37:54.981+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:37:54.981+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:37:54.995+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:37:54.994+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:37:54.996+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:37:54.996+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:37:54.999+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:37:55.006+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:37:55.006+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:37:55.011+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:37:55.011+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:37:55.017+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.425 seconds
[2025-08-06T15:38:25.324+0000] {processor.py:161} INFO - Started process (PID=212) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:38:25.328+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:38:25.330+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:38:25.330+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:38:25.799+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:38:25.799+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:38:25.811+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:38:25.811+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:38:25.813+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:38:25.813+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:38:25.817+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:38:25.824+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:38:25.824+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:38:25.828+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:38:25.828+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:38:25.836+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.521 seconds
[2025-08-06T15:38:56.158+0000] {processor.py:161} INFO - Started process (PID=218) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:38:56.160+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:38:56.164+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:38:56.163+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:38:56.537+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:38:56.537+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:38:56.545+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:38:56.545+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:38:56.547+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:38:56.546+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:38:56.549+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:38:56.555+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:38:56.555+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:38:56.562+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:38:56.562+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:38:56.569+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.420 seconds
[2025-08-06T15:39:26.890+0000] {processor.py:161} INFO - Started process (PID=224) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:39:26.892+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:39:26.896+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:39:26.896+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:39:27.281+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:39:27.280+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:39:27.292+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:39:27.292+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:39:27.294+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:39:27.294+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:39:27.297+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:39:27.303+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:39:27.303+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:39:27.308+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:39:27.308+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:39:27.314+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.436 seconds
[2025-08-06T15:39:57.683+0000] {processor.py:161} INFO - Started process (PID=230) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:39:57.684+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:39:57.687+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:39:57.686+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:39:58.068+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:39:58.068+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:39:58.079+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:39:58.079+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:39:58.081+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:39:58.081+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:39:58.085+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:39:58.092+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:39:58.092+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:39:58.096+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:39:58.096+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:39:58.102+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.428 seconds
[2025-08-06T15:40:28.415+0000] {processor.py:161} INFO - Started process (PID=236) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:40:28.417+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:40:28.420+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:40:28.420+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:40:28.788+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:40:28.788+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:40:28.797+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:40:28.797+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:40:28.798+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:40:28.798+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:40:28.801+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:40:28.807+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:40:28.807+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:40:28.812+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:40:28.812+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:40:28.818+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.416 seconds
[2025-08-06T15:40:59.165+0000] {processor.py:161} INFO - Started process (PID=242) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:40:59.167+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:40:59.171+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:40:59.170+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:40:59.590+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:40:59.589+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:40:59.602+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:40:59.602+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:40:59.603+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:40:59.602+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:40:59.606+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:40:59.617+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:40:59.617+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:40:59.624+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:40:59.623+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:40:59.631+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.477 seconds
[2025-08-06T15:41:29.991+0000] {processor.py:161} INFO - Started process (PID=248) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:41:29.993+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:41:29.996+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:41:29.996+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:41:30.376+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:41:30.376+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:41:30.388+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:41:30.388+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:41:30.390+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:41:30.390+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:41:30.394+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:41:30.400+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:41:30.400+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:41:30.404+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:41:30.404+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:41:30.410+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.433 seconds
[2025-08-06T15:42:00.761+0000] {processor.py:161} INFO - Started process (PID=254) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:42:00.762+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:42:00.766+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:42:00.765+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:42:01.153+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:42:01.152+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:42:01.162+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:42:01.162+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:42:01.163+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:42:01.162+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:42:01.165+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:42:01.173+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:42:01.173+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:42:01.178+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:42:01.177+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:42:01.184+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.440 seconds
[2025-08-06T15:42:31.533+0000] {processor.py:161} INFO - Started process (PID=260) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:42:31.535+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:42:31.537+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:42:31.537+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:42:31.889+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:42:31.889+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:42:31.897+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:42:31.897+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:42:31.899+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:42:31.899+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:42:31.901+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:42:31.907+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:42:31.907+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:42:31.912+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:42:31.912+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:42:31.919+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.394 seconds
[2025-08-06T15:43:02.252+0000] {processor.py:161} INFO - Started process (PID=266) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:43:02.253+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:43:02.256+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:43:02.256+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:43:02.616+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:43:02.615+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:43:02.624+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:43:02.624+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:43:02.625+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:43:02.625+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:43:02.628+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:43:02.634+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:43:02.634+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:43:02.638+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:43:02.638+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:43:02.645+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.405 seconds
[2025-08-06T15:43:32.970+0000] {processor.py:161} INFO - Started process (PID=272) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:43:32.973+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:43:32.976+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:43:32.976+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:43:33.376+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:43:33.376+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:43:33.390+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:43:33.390+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:43:33.391+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:43:33.390+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:43:33.393+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:43:33.400+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:43:33.400+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:43:33.405+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:43:33.405+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:43:33.411+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.455 seconds
[2025-08-06T15:44:03.769+0000] {processor.py:161} INFO - Started process (PID=278) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:44:03.770+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:44:03.772+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:44:03.772+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:44:04.162+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:44:04.162+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:44:04.182+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:44:04.182+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:44:04.185+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:44:04.185+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:44:04.188+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:44:04.195+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:44:04.194+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:44:04.199+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:44:04.199+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:44:04.206+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.447 seconds
[2025-08-06T15:44:34.600+0000] {processor.py:161} INFO - Started process (PID=284) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:44:34.602+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:44:34.609+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:44:34.608+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:44:34.966+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:44:34.966+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:44:34.978+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:44:34.978+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:44:34.979+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:44:34.979+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:44:34.982+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:44:34.988+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:44:34.988+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:44:34.993+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:44:34.993+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:44:34.999+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.407 seconds
[2025-08-06T15:45:05.327+0000] {processor.py:161} INFO - Started process (PID=290) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:45:05.329+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:45:05.333+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:45:05.333+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:45:05.714+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:45:05.714+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:45:05.723+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:45:05.723+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:45:05.724+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:45:05.724+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:45:05.727+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:45:05.733+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:45:05.733+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:45:05.738+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:45:05.738+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:45:05.746+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.429 seconds
[2025-08-06T15:45:36.104+0000] {processor.py:161} INFO - Started process (PID=296) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:45:36.106+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:45:36.109+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:45:36.109+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:45:36.503+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:45:36.503+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:45:36.512+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:45:36.512+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:45:36.513+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:45:36.513+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:45:36.515+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:45:36.522+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:45:36.522+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:45:36.527+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:45:36.526+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:45:36.533+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.442 seconds
[2025-08-06T15:46:06.850+0000] {processor.py:161} INFO - Started process (PID=302) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:46:06.852+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:46:06.855+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:46:06.854+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:46:07.224+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:46:07.224+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:46:07.233+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:46:07.233+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:46:07.235+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:46:07.234+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:46:07.237+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:46:07.243+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:46:07.243+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:46:07.248+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:46:07.247+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:46:07.259+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.418 seconds
[2025-08-06T15:46:37.643+0000] {processor.py:161} INFO - Started process (PID=308) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:46:37.647+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:46:37.650+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:46:37.650+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:46:38.037+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:46:38.037+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:46:38.052+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:46:38.052+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:46:38.053+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:46:38.053+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:46:38.056+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:46:38.062+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:46:38.062+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:46:38.067+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:46:38.067+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:46:38.074+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.445 seconds
[2025-08-06T15:47:08.441+0000] {processor.py:161} INFO - Started process (PID=314) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:47:08.444+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:47:08.454+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:47:08.453+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:47:08.824+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:47:08.824+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:47:08.839+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:47:08.838+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:47:08.839+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:47:08.839+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:47:08.842+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:47:08.848+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:47:08.848+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:47:08.853+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:47:08.853+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:47:08.860+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.428 seconds
[2025-08-06T15:47:39.148+0000] {processor.py:161} INFO - Started process (PID=320) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:47:39.152+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:47:39.156+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:47:39.156+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:47:39.532+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:47:39.532+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:47:39.541+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:47:39.541+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:47:39.542+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:47:39.542+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:47:39.546+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:47:39.552+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:47:39.552+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:47:39.556+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:47:39.556+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:47:39.564+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.425 seconds
[2025-08-06T15:48:09.946+0000] {processor.py:161} INFO - Started process (PID=326) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:48:09.948+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:48:09.952+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:48:09.952+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:48:10.306+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:48:10.306+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:48:10.317+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:48:10.317+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:48:10.318+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:48:10.318+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:48:10.321+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:48:10.328+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:48:10.328+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:48:10.332+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:48:10.332+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:48:10.341+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.405 seconds
[2025-08-06T15:48:40.660+0000] {processor.py:161} INFO - Started process (PID=332) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:48:40.661+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:48:40.663+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:48:40.663+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:48:41.010+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:48:41.010+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:48:41.022+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:48:41.022+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:48:41.024+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:48:41.023+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:48:41.026+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:48:41.033+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:48:41.032+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:48:41.037+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:48:41.037+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:48:41.043+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.392 seconds
[2025-08-06T15:49:11.394+0000] {processor.py:161} INFO - Started process (PID=338) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:49:11.397+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:49:11.400+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:49:11.400+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:49:11.786+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:49:11.786+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:49:11.796+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:49:11.796+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:49:11.797+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:49:11.797+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:49:11.800+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:49:11.806+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:49:11.806+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:49:11.810+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:49:11.810+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:49:11.820+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.434 seconds
[2025-08-06T15:49:42.156+0000] {processor.py:161} INFO - Started process (PID=344) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:49:42.157+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:49:42.160+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:49:42.160+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:49:42.543+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:49:42.542+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:49:42.552+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:49:42.552+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:49:42.553+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:49:42.553+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:49:42.559+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:49:42.565+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:49:42.565+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:49:42.569+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:49:42.569+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:49:42.577+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.432 seconds
[2025-08-06T15:50:12.895+0000] {processor.py:161} INFO - Started process (PID=350) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:50:12.897+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:50:12.900+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:50:12.900+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:50:13.276+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:50:13.276+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:50:13.289+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:50:13.289+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:50:13.291+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:50:13.291+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:50:13.294+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:50:13.300+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:50:13.300+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:50:13.305+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:50:13.305+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:50:13.311+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.429 seconds
[2025-08-06T15:50:43.665+0000] {processor.py:161} INFO - Started process (PID=356) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:50:43.666+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:50:43.669+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:50:43.669+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:50:44.041+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:50:44.041+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:50:44.054+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:50:44.054+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:50:44.056+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:50:44.056+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:50:44.058+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:50:44.065+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:50:44.065+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:50:44.069+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:50:44.069+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:50:44.075+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.424 seconds
[2025-08-06T15:51:14.375+0000] {processor.py:161} INFO - Started process (PID=362) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:51:14.376+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:51:14.378+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:51:14.377+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:51:14.734+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:51:14.734+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:51:14.746+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:51:14.746+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:51:14.747+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:51:14.747+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:51:14.751+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:51:14.760+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:51:14.760+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:51:14.767+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:51:14.767+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:51:14.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.409 seconds
[2025-08-06T15:51:45.103+0000] {processor.py:161} INFO - Started process (PID=368) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:51:45.105+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:51:45.107+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:51:45.107+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:51:45.487+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:51:45.486+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:51:45.495+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:51:45.495+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:51:45.496+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:51:45.496+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:51:45.499+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:51:45.510+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:51:45.510+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:51:45.514+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:51:45.514+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:51:45.521+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.429 seconds
[2025-08-06T15:52:15.808+0000] {processor.py:161} INFO - Started process (PID=374) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:52:15.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:52:15.815+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:52:15.813+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:52:16.192+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:52:16.192+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:52:16.206+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:52:16.206+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:52:16.207+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:52:16.207+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:52:16.209+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:52:16.216+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:52:16.216+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:52:16.220+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:52:16.220+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:52:16.226+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.428 seconds
[2025-08-06T15:52:46.562+0000] {processor.py:161} INFO - Started process (PID=380) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:52:46.564+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:52:46.566+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:52:46.566+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:52:46.945+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:52:46.945+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:52:46.954+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:52:46.954+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:52:46.955+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:52:46.955+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:52:46.957+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:52:46.964+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:52:46.964+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:52:46.968+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:52:46.968+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:52:46.974+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.421 seconds
[2025-08-06T15:53:17.326+0000] {processor.py:161} INFO - Started process (PID=386) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:53:17.329+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:53:17.332+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:53:17.331+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:53:17.699+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:53:17.699+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:53:17.710+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:53:17.710+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:53:17.712+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:53:17.712+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:53:17.720+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:53:17.726+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:53:17.726+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:53:17.731+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:53:17.731+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:53:17.738+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.422 seconds
[2025-08-06T15:53:48.099+0000] {processor.py:161} INFO - Started process (PID=392) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:53:48.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:53:48.102+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:53:48.102+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:53:48.466+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:53:48.466+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:53:48.475+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:53:48.475+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:53:48.477+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:53:48.476+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:53:48.479+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:53:48.488+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:53:48.488+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:53:48.493+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:53:48.493+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:53:48.499+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.408 seconds
[2025-08-06T15:54:18.850+0000] {processor.py:161} INFO - Started process (PID=398) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:54:18.851+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:54:18.855+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:54:18.854+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:54:19.243+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:54:19.243+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:54:19.253+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:54:19.253+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:54:19.258+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:54:19.258+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:54:19.261+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:54:19.268+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:54:19.268+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:54:19.272+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:54:19.272+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:54:19.279+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.442 seconds
[2025-08-06T15:54:49.609+0000] {processor.py:161} INFO - Started process (PID=404) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:54:49.610+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:54:49.612+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:54:49.612+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:54:49.973+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:54:49.973+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:54:49.985+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:54:49.985+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:54:49.989+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:54:49.989+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:54:49.992+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:54:49.998+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:54:49.998+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:54:50.002+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:54:50.002+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:54:50.009+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.407 seconds
[2025-08-06T15:55:20.339+0000] {processor.py:161} INFO - Started process (PID=410) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:55:20.341+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:55:20.343+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:55:20.343+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:55:20.811+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:55:20.811+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:55:20.826+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:55:20.826+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:55:20.829+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:55:20.829+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:55:20.833+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:55:20.840+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:55:20.840+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:55:20.845+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:55:20.845+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:55:20.853+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.525 seconds
[2025-08-06T15:55:51.166+0000] {processor.py:161} INFO - Started process (PID=416) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:55:51.167+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:55:51.171+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:55:51.169+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:55:51.548+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:55:51.548+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:55:51.565+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:55:51.565+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:55:51.566+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:55:51.565+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:55:51.569+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:55:51.575+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:55:51.575+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:55:51.580+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:55:51.580+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:55:51.587+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.428 seconds
[2025-08-06T15:56:21.958+0000] {processor.py:161} INFO - Started process (PID=422) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:56:21.959+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:56:21.971+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:56:21.970+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:56:22.385+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:56:22.385+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:56:22.402+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:56:22.401+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:56:22.403+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:56:22.402+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:56:22.407+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:56:22.429+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:56:22.429+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:56:22.438+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:56:22.438+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:56:22.461+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.513 seconds
[2025-08-06T15:56:52.772+0000] {processor.py:161} INFO - Started process (PID=428) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:56:52.774+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:56:52.782+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:56:52.780+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:56:53.160+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:56:53.159+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:56:53.171+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:56:53.171+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:56:53.172+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:56:53.172+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:56:53.175+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:56:53.182+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:56:53.182+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:56:53.186+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:56:53.186+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:56:53.192+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.429 seconds
[2025-08-06T15:57:23.521+0000] {processor.py:161} INFO - Started process (PID=434) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:57:23.523+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:57:23.526+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:57:23.526+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:57:23.932+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:57:23.932+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:57:24.009+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:57:24.009+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:57:24.033+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:57:24.033+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:57:24.041+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:57:24.049+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:57:24.049+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:57:24.055+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:57:24.055+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:57:24.062+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.550 seconds
[2025-08-06T15:57:54.339+0000] {processor.py:161} INFO - Started process (PID=440) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:57:54.341+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:57:54.344+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:57:54.343+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:57:54.702+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:57:54.702+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:57:54.713+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:57:54.713+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:57:54.715+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:57:54.715+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:57:54.717+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:57:54.723+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:57:54.723+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:57:54.727+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:57:54.727+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:57:54.734+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.406 seconds
[2025-08-06T15:58:25.058+0000] {processor.py:161} INFO - Started process (PID=446) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:58:25.060+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:58:25.062+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:58:25.062+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:58:25.423+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:58:25.423+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:58:25.434+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:58:25.433+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:58:25.434+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:58:25.434+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:58:25.437+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:58:25.447+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:58:25.447+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:58:25.451+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:58:25.451+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:58:25.458+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.407 seconds
[2025-08-06T15:58:55.756+0000] {processor.py:161} INFO - Started process (PID=452) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:58:55.758+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:58:55.760+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:58:55.759+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:58:56.177+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:58:56.177+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:58:56.186+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:58:56.186+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:58:56.188+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:58:56.188+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:58:56.191+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:58:56.198+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:58:56.198+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:58:56.202+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:58:56.202+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:58:56.210+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.464 seconds
[2025-08-06T15:59:26.496+0000] {processor.py:161} INFO - Started process (PID=507) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:59:26.499+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:59:26.503+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:59:26.502+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:59:26.906+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:59:26.906+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:59:26.914+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:59:26.914+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:59:26.915+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:59:26.915+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:59:26.918+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:59:26.925+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:59:26.925+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:59:26.930+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:59:26.930+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:59:26.939+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.459 seconds
[2025-08-06T15:59:57.284+0000] {processor.py:161} INFO - Started process (PID=513) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:59:57.285+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T15:59:57.287+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:59:57.287+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:59:57.657+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:59:57.657+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T15:59:57.668+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:59:57.668+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T15:59:57.668+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:59:57.668+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T15:59:57.671+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T15:59:57.677+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:59:57.677+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T15:59:57.681+0000] {logging_mixin.py:188} INFO - [2025-08-06T15:59:57.681+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T15:59:57.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.412 seconds
[2025-08-06T16:00:28.016+0000] {processor.py:161} INFO - Started process (PID=519) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:00:28.017+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:00:28.020+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:00:28.019+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:00:28.409+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:00:28.408+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:00:28.424+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:00:28.424+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:00:28.425+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:00:28.425+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:00:28.428+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:00:28.434+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:00:28.434+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:00:28.438+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:00:28.438+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:00:28.445+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.436 seconds
[2025-08-06T16:00:58.826+0000] {processor.py:161} INFO - Started process (PID=525) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:00:58.827+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:00:58.832+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:00:58.830+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:00:59.217+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:00:59.217+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:00:59.227+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:00:59.227+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:00:59.228+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:00:59.228+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:00:59.233+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:00:59.239+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:00:59.239+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:00:59.243+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:00:59.243+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:00:59.250+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.431 seconds
[2025-08-06T16:01:29.545+0000] {processor.py:161} INFO - Started process (PID=531) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:01:29.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:01:29.549+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:01:29.549+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:01:29.939+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:01:29.939+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:01:29.951+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:01:29.951+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:01:29.958+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:01:29.957+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:01:29.961+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:01:29.968+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:01:29.968+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:01:29.972+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:01:29.972+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:01:29.979+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.442 seconds
[2025-08-06T16:02:00.314+0000] {processor.py:161} INFO - Started process (PID=537) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:02:00.316+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:02:00.319+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:02:00.318+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:02:00.702+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:02:00.702+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:02:00.711+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:02:00.711+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:02:00.715+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:02:00.715+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:02:00.718+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:02:00.724+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:02:00.724+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:02:00.729+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:02:00.729+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:02:00.736+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.435 seconds
[2025-08-06T16:02:31.096+0000] {processor.py:161} INFO - Started process (PID=543) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:02:31.098+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:02:31.102+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:02:31.101+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:02:31.539+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:02:31.539+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:02:31.552+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:02:31.552+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:02:31.553+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:02:31.553+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:02:31.556+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:02:31.562+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:02:31.562+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:02:31.566+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:02:31.566+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:02:31.573+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.491 seconds
[2025-08-06T16:03:01.937+0000] {processor.py:161} INFO - Started process (PID=549) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:03:01.938+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:03:01.941+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:03:01.940+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:03:02.357+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:03:02.357+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:03:02.375+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:03:02.375+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:03:02.377+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:03:02.377+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:03:02.380+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:03:02.390+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:03:02.390+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:03:02.399+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:03:02.399+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:03:02.409+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.480 seconds
[2025-08-06T16:03:32.724+0000] {processor.py:161} INFO - Started process (PID=555) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:03:32.725+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:03:32.729+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:03:32.728+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:03:33.236+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:03:33.236+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:03:33.247+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:03:33.247+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:03:33.248+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:03:33.247+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:03:33.251+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:03:33.257+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:03:33.257+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:03:33.262+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:03:33.262+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:03:33.270+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.551 seconds
[2025-08-06T16:04:03.665+0000] {processor.py:161} INFO - Started process (PID=561) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:04:03.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:04:03.671+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:04:03.670+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:04:04.121+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:04:04.121+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:04:04.189+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:04:04.189+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:04:04.205+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:04:04.205+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:04:04.210+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:04:04.218+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:04:04.218+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:04:04.225+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:04:04.225+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:04:04.233+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.580 seconds
[2025-08-06T16:04:34.450+0000] {processor.py:161} INFO - Started process (PID=567) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:04:34.455+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:04:34.458+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:04:34.457+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:04:34.887+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:04:34.887+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:04:34.897+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:04:34.897+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:04:34.898+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:04:34.898+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:04:34.901+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:04:34.908+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:04:34.908+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:04:34.912+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:04:34.912+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:04:34.920+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.481 seconds
[2025-08-06T16:05:05.282+0000] {processor.py:161} INFO - Started process (PID=610) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:05:05.283+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:05:05.285+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:05:05.285+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:05:05.775+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:05:05.775+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:05:05.803+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:05:05.803+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:05:05.814+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:05:05.814+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:05:05.819+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:05:05.832+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:05:05.832+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:05:05.840+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:05:05.840+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:05:05.854+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.580 seconds
[2025-08-06T16:05:36.235+0000] {processor.py:161} INFO - Started process (PID=628) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:05:36.238+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:05:36.241+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:05:36.241+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:05:36.667+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:05:36.666+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:05:36.677+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:05:36.677+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:05:36.678+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:05:36.678+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:05:36.681+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:05:36.687+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:05:36.687+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:05:36.692+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:05:36.692+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:05:36.698+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.479 seconds
[2025-08-06T16:06:07.036+0000] {processor.py:161} INFO - Started process (PID=634) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:06:07.038+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:06:07.043+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:06:07.043+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:06:07.458+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:06:07.457+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:06:07.469+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:06:07.469+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:06:07.470+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:06:07.470+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:06:07.472+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:06:07.482+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:06:07.481+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:06:07.487+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:06:07.487+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:06:07.493+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.472 seconds
[2025-08-06T16:06:37.869+0000] {processor.py:161} INFO - Started process (PID=640) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:06:37.871+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:06:37.875+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:06:37.874+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:06:38.272+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:06:38.272+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:06:38.285+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:06:38.285+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:06:38.286+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:06:38.286+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:06:38.289+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:06:38.295+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:06:38.295+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:06:38.299+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:06:38.299+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:06:38.305+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.452 seconds
[2025-08-06T16:07:08.669+0000] {processor.py:161} INFO - Started process (PID=646) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:07:08.671+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:07:08.675+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:07:08.674+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:07:09.110+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:07:09.110+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:07:09.122+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:07:09.122+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:07:09.122+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:07:09.122+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:07:09.125+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:07:09.131+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:07:09.131+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:07:09.136+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:07:09.136+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:07:09.143+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.491 seconds
[2025-08-06T16:07:39.519+0000] {processor.py:161} INFO - Started process (PID=652) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:07:39.521+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:07:39.525+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:07:39.524+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:07:39.986+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:07:39.986+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:07:40.037+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:07:40.037+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:07:40.051+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:07:40.051+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:07:40.055+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:07:40.062+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:07:40.062+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:07:40.067+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:07:40.067+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:07:40.074+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.569 seconds
[2025-08-06T16:08:10.366+0000] {processor.py:161} INFO - Started process (PID=658) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:08:10.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:08:10.373+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:08:10.372+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:08:10.775+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:08:10.775+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:08:10.795+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:08:10.795+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:08:10.797+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:08:10.797+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:08:10.800+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:08:10.806+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:08:10.806+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:08:10.811+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:08:10.811+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:08:10.818+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.465 seconds
[2025-08-06T16:08:41.127+0000] {processor.py:161} INFO - Started process (PID=664) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:08:41.129+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:08:41.131+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:08:41.131+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:08:41.575+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:08:41.575+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:08:41.599+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:08:41.599+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:08:41.602+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:08:41.602+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:08:41.605+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:08:41.612+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:08:41.612+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:08:41.620+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:08:41.620+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:08:41.627+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.510 seconds
[2025-08-06T16:09:12.015+0000] {processor.py:161} INFO - Started process (PID=670) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:09:12.018+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:09:12.021+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:09:12.021+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:09:12.443+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:09:12.443+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:09:12.464+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:09:12.463+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:09:12.466+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:09:12.466+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:09:12.469+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:09:12.476+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:09:12.475+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:09:12.480+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:09:12.480+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:09:12.486+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.485 seconds
[2025-08-06T16:09:42.805+0000] {processor.py:161} INFO - Started process (PID=676) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:09:42.807+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:09:42.809+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:09:42.809+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:09:43.160+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:09:43.160+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:09:43.170+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:09:43.170+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:09:43.171+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:09:43.171+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:09:43.174+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:09:43.181+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:09:43.181+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:09:43.185+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:09:43.185+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:09:43.191+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.395 seconds
[2025-08-06T16:10:13.546+0000] {processor.py:161} INFO - Started process (PID=687) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:10:13.549+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:10:13.551+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:10:13.551+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:10:13.953+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:10:13.953+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:10:13.964+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:10:13.964+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:10:13.965+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:10:13.965+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:10:13.968+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:10:13.974+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:10:13.974+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:10:13.978+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:10:13.978+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:10:13.985+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.453 seconds
[2025-08-06T16:10:44.397+0000] {processor.py:161} INFO - Started process (PID=693) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:10:44.399+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:10:44.402+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:10:44.401+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:10:44.818+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:10:44.818+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:10:44.869+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:10:44.869+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:10:44.881+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:10:44.881+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:10:44.884+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:10:44.892+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:10:44.892+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:10:44.897+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:10:44.897+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:10:44.904+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.527 seconds
[2025-08-06T16:11:15.275+0000] {processor.py:161} INFO - Started process (PID=699) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:11:15.277+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:11:15.279+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:11:15.279+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:11:15.700+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:11:15.700+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:11:15.711+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:11:15.711+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:11:15.712+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:11:15.712+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:11:15.715+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:11:15.721+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:11:15.720+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:11:15.725+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:11:15.725+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:11:15.733+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.468 seconds
[2025-08-06T16:11:46.103+0000] {processor.py:161} INFO - Started process (PID=705) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:11:46.105+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:11:46.107+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:11:46.107+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:11:46.493+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:11:46.493+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:11:46.504+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:11:46.503+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:11:46.505+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:11:46.505+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:11:46.508+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:11:46.515+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:11:46.514+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:11:46.519+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:11:46.519+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:11:46.526+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.433 seconds
[2025-08-06T16:12:16.907+0000] {processor.py:161} INFO - Started process (PID=711) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:12:16.910+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:12:16.913+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:12:16.912+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:12:17.305+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:12:17.305+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:12:17.313+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:12:17.313+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:12:17.315+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:12:17.315+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:12:17.318+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:12:17.324+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:12:17.324+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:12:17.329+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:12:17.329+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:12:17.335+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.445 seconds
[2025-08-06T16:12:47.741+0000] {processor.py:161} INFO - Started process (PID=717) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:12:47.743+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:12:47.746+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:12:47.746+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:12:48.128+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:12:48.128+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:12:48.201+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:12:48.201+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:12:48.222+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:12:48.222+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:12:48.226+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:12:48.235+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:12:48.235+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:12:48.241+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:12:48.241+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:12:48.248+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.518 seconds
[2025-08-06T16:13:18.560+0000] {processor.py:161} INFO - Started process (PID=723) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:13:18.563+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:13:18.570+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:13:18.569+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:13:18.967+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:13:18.967+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:13:18.979+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:13:18.979+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:13:18.980+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:13:18.980+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:13:18.983+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:13:18.989+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:13:18.989+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:13:18.993+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:13:18.993+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:13:18.999+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.452 seconds
[2025-08-06T16:13:49.329+0000] {processor.py:161} INFO - Started process (PID=729) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:13:49.331+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:13:49.334+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:13:49.333+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:13:49.614+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:13:49.614+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:13:49.622+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:13:49.621+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:13:49.622+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:13:49.622+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:13:49.625+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:13:49.631+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:13:49.631+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:13:49.635+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:13:49.635+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:13:49.641+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.322 seconds
[2025-08-06T16:14:19.958+0000] {processor.py:161} INFO - Started process (PID=735) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:14:19.959+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:14:19.962+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:14:19.961+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:14:20.281+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:14:20.281+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:14:20.289+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:14:20.289+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:14:20.291+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:14:20.291+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:14:20.294+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:14:20.300+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:14:20.300+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:14:20.304+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:14:20.304+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:14:20.311+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.360 seconds
[2025-08-06T16:14:50.615+0000] {processor.py:161} INFO - Started process (PID=741) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:14:50.616+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:14:50.619+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:14:50.619+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:14:50.940+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:14:50.940+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:14:50.945+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:14:50.945+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:14:50.946+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:14:50.946+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:14:50.948+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:14:50.953+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:14:50.953+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:14:50.958+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:14:50.958+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:14:50.964+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.360 seconds
[2025-08-06T16:15:21.314+0000] {processor.py:161} INFO - Started process (PID=747) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:15:21.316+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:15:21.319+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:15:21.319+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:15:21.678+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:15:21.677+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:15:21.687+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:15:21.687+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:15:21.689+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:15:21.689+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:15:21.692+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:15:21.699+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:15:21.699+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:15:21.703+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:15:21.703+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:15:21.709+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.405 seconds
[2025-08-06T16:15:52.080+0000] {processor.py:161} INFO - Started process (PID=753) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:15:52.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:15:52.084+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:15:52.084+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:15:52.463+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:15:52.462+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:15:52.473+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:15:52.472+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:15:52.474+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:15:52.474+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:15:52.476+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:15:52.482+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:15:52.482+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:15:52.486+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:15:52.486+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:15:52.492+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.430 seconds
[2025-08-06T16:16:22.863+0000] {processor.py:161} INFO - Started process (PID=759) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:16:22.865+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:16:22.868+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:16:22.867+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:16:23.281+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:16:23.281+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:16:23.291+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:16:23.291+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:16:23.293+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:16:23.292+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:16:23.295+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:16:23.302+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:16:23.302+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:16:23.306+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:16:23.306+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:16:23.314+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.467 seconds
[2025-08-06T16:16:53.675+0000] {processor.py:161} INFO - Started process (PID=770) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:16:53.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:16:53.682+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:16:53.681+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:16:54.080+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:16:54.080+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:16:54.093+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:16:54.093+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:16:54.094+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:16:54.094+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:16:54.097+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:16:54.103+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:16:54.103+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:16:54.107+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:16:54.107+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:16:54.113+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.454 seconds
[2025-08-06T16:17:24.484+0000] {processor.py:161} INFO - Started process (PID=776) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:17:24.486+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:17:24.488+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:17:24.488+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:17:24.885+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:17:24.885+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:17:24.897+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:17:24.897+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:17:24.899+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:17:24.898+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:17:24.901+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:17:24.907+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:17:24.907+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:17:24.912+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:17:24.912+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:17:24.919+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.451 seconds
[2025-08-06T16:17:55.312+0000] {processor.py:161} INFO - Started process (PID=782) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:17:55.313+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:17:55.322+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:17:55.321+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:17:55.740+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:17:55.740+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:17:55.749+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:17:55.749+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:17:55.750+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:17:55.750+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:17:55.754+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:17:55.760+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:17:55.760+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:17:55.765+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:17:55.765+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:17:55.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.480 seconds
[2025-08-06T16:18:26.128+0000] {processor.py:161} INFO - Started process (PID=813) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:18:26.129+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:18:26.131+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:18:26.131+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:18:26.642+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:18:26.642+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:18:26.649+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:18:26.649+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:18:26.650+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:18:26.650+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:18:26.653+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:18:26.661+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:18:26.661+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:18:26.667+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:18:26.667+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:18:26.677+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.556 seconds
[2025-08-06T16:18:57.053+0000] {processor.py:161} INFO - Started process (PID=823) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:18:57.054+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:18:57.056+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:18:57.056+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:18:57.480+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:18:57.480+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:18:57.493+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:18:57.493+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:18:57.494+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:18:57.494+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:18:57.497+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:18:57.504+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:18:57.504+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:18:57.510+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:18:57.510+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:18:57.517+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.472 seconds
[2025-08-06T16:19:27.755+0000] {processor.py:161} INFO - Started process (PID=829) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:19:27.757+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:19:27.763+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:19:27.762+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:19:28.155+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:19:28.155+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:19:28.163+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:19:28.163+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:19:28.165+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:19:28.164+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:19:28.169+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:19:28.177+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:19:28.177+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:19:28.181+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:19:28.181+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:19:28.188+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.442 seconds
[2025-08-06T16:19:58.557+0000] {processor.py:161} INFO - Started process (PID=835) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:19:58.559+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:19:58.562+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:19:58.562+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:19:58.970+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:19:58.970+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:19:58.981+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:19:58.981+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:19:58.982+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:19:58.982+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:19:58.986+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:19:58.993+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:19:58.993+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:19:58.998+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:19:58.998+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:19:59.006+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.458 seconds
[2025-08-06T16:20:29.317+0000] {processor.py:161} INFO - Started process (PID=841) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:20:29.318+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:20:29.321+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:20:29.320+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:20:29.762+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:20:29.762+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:20:29.778+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:20:29.778+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:20:29.779+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:20:29.779+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:20:29.782+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:20:29.789+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:20:29.789+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:20:29.793+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:20:29.793+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:20:29.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.494 seconds
[2025-08-06T16:21:00.148+0000] {processor.py:161} INFO - Started process (PID=847) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:21:00.149+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:21:00.152+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:21:00.151+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:21:00.562+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:21:00.562+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:21:00.623+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:21:00.623+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:21:00.640+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:21:00.640+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:21:00.644+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:21:00.653+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:21:00.653+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:21:00.659+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:21:00.659+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:21:00.666+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.526 seconds
[2025-08-06T16:21:30.950+0000] {processor.py:161} INFO - Started process (PID=853) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:21:30.952+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:21:30.955+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:21:30.955+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:21:31.387+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:21:31.386+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:21:31.396+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:21:31.396+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:21:31.397+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:21:31.397+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:21:31.400+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:21:31.406+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:21:31.406+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:21:31.411+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:21:31.411+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:21:31.417+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.483 seconds
[2025-08-06T16:22:01.818+0000] {processor.py:161} INFO - Started process (PID=859) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:22:01.820+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:22:01.824+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:22:01.824+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:22:02.273+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:22:02.273+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:22:02.291+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:22:02.290+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:22:02.292+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:22:02.292+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:22:02.296+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:22:02.304+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:22:02.304+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:22:02.309+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:22:02.309+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:22:02.316+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.512 seconds
[2025-08-06T16:22:32.662+0000] {processor.py:161} INFO - Started process (PID=865) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:22:32.663+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:22:32.669+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:22:32.668+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:22:33.105+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:22:33.105+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:22:33.117+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:22:33.117+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:22:33.118+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:22:33.118+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:22:33.121+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:22:33.128+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:22:33.128+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:22:33.133+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:22:33.133+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:22:33.139+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.489 seconds
[2025-08-06T16:23:03.494+0000] {processor.py:161} INFO - Started process (PID=871) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:23:03.495+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:23:03.499+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:23:03.498+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:23:03.926+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:23:03.926+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:23:03.944+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:23:03.944+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:23:03.946+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:23:03.946+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:23:03.949+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:23:03.956+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:23:03.956+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:23:03.960+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:23:03.960+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:23:03.967+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.492 seconds
[2025-08-06T16:23:34.304+0000] {processor.py:161} INFO - Started process (PID=877) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:23:34.307+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:23:34.310+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:23:34.309+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:23:34.735+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:23:34.735+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:23:34.746+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:23:34.746+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:23:34.747+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:23:34.747+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:23:34.750+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:23:34.757+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:23:34.757+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:23:34.762+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:23:34.761+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:23:34.769+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.480 seconds
[2025-08-06T16:24:05.127+0000] {processor.py:161} INFO - Started process (PID=883) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:24:05.129+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:24:05.131+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:24:05.131+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:24:05.724+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:24:05.724+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:24:05.735+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:24:05.735+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:24:05.738+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:24:05.738+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:24:05.744+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:24:05.763+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:24:05.763+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:24:05.778+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:24:05.778+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:24:05.787+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.669 seconds
[2025-08-06T16:24:36.119+0000] {processor.py:161} INFO - Started process (PID=889) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:24:36.122+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:24:36.124+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:24:36.124+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:24:36.591+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:24:36.591+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:24:36.604+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:24:36.603+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:24:36.605+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:24:36.605+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:24:36.608+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:24:36.615+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:24:36.615+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:24:36.620+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:24:36.620+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:24:36.629+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.519 seconds
[2025-08-06T16:25:06.975+0000] {processor.py:161} INFO - Started process (PID=895) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:25:06.977+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:25:06.979+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:25:06.979+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:25:07.536+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:25:07.535+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:25:07.569+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:25:07.568+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:25:07.570+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:25:07.570+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:25:07.580+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:25:07.596+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:25:07.595+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:25:07.604+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:25:07.604+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:25:07.620+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.652 seconds
[2025-08-06T16:25:37.838+0000] {processor.py:161} INFO - Started process (PID=901) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:25:37.840+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:25:37.843+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:25:37.843+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:25:38.498+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:25:38.498+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:25:38.561+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:25:38.561+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:25:38.577+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:25:38.577+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:25:38.582+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:25:38.591+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:25:38.591+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:25:38.600+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:25:38.600+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:25:38.609+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.779 seconds
[2025-08-06T16:26:09.072+0000] {processor.py:161} INFO - Started process (PID=907) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:26:09.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:26:09.076+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:26:09.075+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:26:09.556+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:26:09.555+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:26:09.567+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:26:09.567+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:26:09.569+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:26:09.569+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:26:09.572+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:26:09.581+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:26:09.581+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:26:09.586+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:26:09.586+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:26:09.593+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.529 seconds
[2025-08-06T16:26:39.904+0000] {processor.py:161} INFO - Started process (PID=913) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:26:39.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:26:39.908+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:26:39.907+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:26:40.450+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:26:40.450+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:26:40.461+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:26:40.461+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:26:40.463+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:26:40.463+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:26:40.466+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:26:40.474+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:26:40.474+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:26:40.480+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:26:40.480+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:26:40.486+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.588 seconds
[2025-08-06T16:27:10.744+0000] {processor.py:161} INFO - Started process (PID=919) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:27:10.745+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:27:10.747+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:27:10.747+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:27:11.240+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:27:11.240+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:27:11.251+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:27:11.251+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:27:11.254+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:27:11.254+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:27:11.257+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:27:11.265+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:27:11.264+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:27:11.271+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:27:11.271+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:27:11.279+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.543 seconds
[2025-08-06T16:27:41.754+0000] {processor.py:161} INFO - Started process (PID=925) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:27:41.756+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:27:41.759+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:27:41.759+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:27:42.256+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:27:42.256+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:27:42.270+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:27:42.270+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:27:42.272+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:27:42.271+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:27:42.275+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:27:42.282+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:27:42.282+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:27:42.287+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:27:42.287+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:27:42.294+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.554 seconds
[2025-08-06T16:28:12.551+0000] {processor.py:161} INFO - Started process (PID=931) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:28:12.552+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:28:12.555+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:28:12.554+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:28:13.030+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:28:13.030+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:28:13.042+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:28:13.042+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:28:13.046+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:28:13.046+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:28:13.049+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:28:13.055+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:28:13.055+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:28:13.061+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:28:13.061+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:28:13.070+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.529 seconds
[2025-08-06T16:28:43.381+0000] {processor.py:161} INFO - Started process (PID=937) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:28:43.384+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:28:43.393+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:28:43.393+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:28:43.940+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:28:43.940+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:28:43.952+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:28:43.952+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:28:43.954+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:28:43.953+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:28:43.956+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:28:43.964+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:28:43.964+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:28:43.969+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:28:43.969+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:28:43.976+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.623 seconds
[2025-08-06T16:29:14.269+0000] {processor.py:161} INFO - Started process (PID=943) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:29:14.271+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:29:14.273+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:29:14.273+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:29:14.673+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:29:14.673+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:29:14.687+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:29:14.687+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:29:14.688+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:29:14.688+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:29:14.691+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:29:14.697+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:29:14.697+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:29:14.701+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:29:14.701+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:29:14.707+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.453 seconds
[2025-08-06T16:29:45.072+0000] {processor.py:161} INFO - Started process (PID=949) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:29:45.074+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:29:45.081+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:29:45.080+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:29:45.507+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:29:45.506+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:29:45.517+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:29:45.517+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:29:45.518+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:29:45.518+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:29:45.525+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:29:45.533+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:29:45.533+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:29:45.540+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:29:45.539+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:29:45.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.506 seconds
[2025-08-06T16:30:15.909+0000] {processor.py:161} INFO - Started process (PID=955) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:30:15.911+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:30:15.914+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:30:15.913+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:30:16.322+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:30:16.322+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:30:16.336+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:30:16.336+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:30:16.338+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:30:16.337+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:30:16.341+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:30:16.347+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:30:16.347+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:30:16.352+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:30:16.352+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:30:16.358+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.462 seconds
[2025-08-06T16:30:46.720+0000] {processor.py:161} INFO - Started process (PID=961) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:30:46.722+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:30:46.724+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:30:46.724+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:30:47.167+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:30:47.166+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:30:47.176+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:30:47.176+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:30:47.177+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:30:47.177+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:30:47.180+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:30:47.189+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:30:47.189+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:30:47.196+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:30:47.196+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:30:47.204+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.492 seconds
[2025-08-06T16:31:17.604+0000] {processor.py:161} INFO - Started process (PID=967) to work on /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:31:17.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/extract/mysql_to_s3_dag.py for tasks to queue
[2025-08-06T16:31:17.618+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:31:17.617+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:31:18.030+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:31:18.030+0000] {base.py:84} INFO - Using connection ID 'mysql_local' for task execution.
[2025-08-06T16:31:18.039+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:31:18.039+0000] {sql.py:470} INFO - Running statement: SELECT table_name, s3_path FROM etl_table_config WHERE is_active = TRUE, parameters: None
[2025-08-06T16:31:18.041+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:31:18.040+0000] {sql.py:479} INFO - Rows affected: 5
[2025-08-06T16:31:18.043+0000] {processor.py:840} INFO - DAG(s) 'mysql_to_s3_metadata_dag' retrieved from /opt/airflow/dags/extract/mysql_to_s3_dag.py
[2025-08-06T16:31:18.049+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:31:18.049+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-08-06T16:31:18.053+0000] {logging_mixin.py:188} INFO - [2025-08-06T16:31:18.053+0000] {dag.py:3954} INFO - Setting next_dagrun for mysql_to_s3_metadata_dag to None, run_after=None
[2025-08-06T16:31:18.059+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/extract/mysql_to_s3_dag.py took 0.471 seconds
