[2025-08-07T00:09:11.990+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-08-07T00:09:11.999+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: s3_to_snowflake_loader.load_transactions_to_snowflake manual__2025-08-07T00:09:07.574394+00:00 [queued]>
[2025-08-07T00:09:12.005+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: s3_to_snowflake_loader.load_transactions_to_snowflake manual__2025-08-07T00:09:07.574394+00:00 [queued]>
[2025-08-07T00:09:12.006+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-08-07T00:09:12.027+0000] {taskinstance.py:2330} INFO - Executing <Task(SnowflakeOperator): load_transactions_to_snowflake> on 2025-08-07 00:09:07.574394+00:00
[2025-08-07T00:09:12.046+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 's3_to_snowflake_loader', 'load_transactions_to_snowflake', 'manual__2025-08-07T00:09:07.574394+00:00', '--job-id', '77', '--raw', '--subdir', 'DAGS_FOLDER/load/s3_to_snowflake_loader.py', '--cfg-path', '/tmp/tmp3gv5yq_f']
[2025-08-07T00:09:12.048+0000] {standard_task_runner.py:91} INFO - Job 77: Subtask load_transactions_to_snowflake
[2025-08-07T00:09:12.053+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=8016) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-08-07T00:09:12.054+0000] {standard_task_runner.py:63} INFO - Started process 8034 to run task
[2025-08-07T00:09:12.107+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-08-07T00:09:12.213+0000] {task_command.py:426} INFO - Running <TaskInstance: s3_to_snowflake_loader.load_transactions_to_snowflake manual__2025-08-07T00:09:07.574394+00:00 [running]> on host 3bffe12d583b
[2025-08-07T00:09:12.309+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='s3_to_snowflake_loader' AIRFLOW_CTX_TASK_ID='load_transactions_to_snowflake' AIRFLOW_CTX_EXECUTION_DATE='2025-08-07T00:09:07.574394+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-08-07T00:09:07.574394+00:00'
[2025-08-07T00:09:12.312+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-08-07T00:09:12.327+0000] {sql.py:276} INFO - Executing: 
            COPY INTO RAW_TRANSACTIONS
            FROM 's3://favorita-retail-pipeline/raw/transactions.csv'
            CREDENTIALS = (
                AWS_KEY_ID= 'ASIAVX5O2PQE76MTG36M',
                AWS_SECRET_KEY= '***',
                AWS_TOKEN= '***'
            )
            FILE_FORMAT = (TYPE = 'CSV' FIELD_OPTIONALLY_ENCLOSED_BY = '"' SKIP_HEADER = 1);
            
[2025-08-07T00:09:12.341+0000] {base.py:84} INFO - Using connection ID 'snowflake_conn_id' for task execution.
[2025-08-07T00:09:12.351+0000] {base.py:84} INFO - Using connection ID 'snowflake_conn_id' for task execution.
[2025-08-07T00:09:12.355+0000] {connection.py:399} INFO - Snowflake Connector for Python Version: 3.10.0, Python Version: 3.12.3, Platform: Linux-6.10.14-linuxkit-aarch64-with-glibc2.36
[2025-08-07T00:09:12.357+0000] {connection.py:1239} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-08-07T00:09:12.998+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2025-08-07T00:09:12.999+0000] {sql.py:470} INFO - Running statement: COPY INTO RAW_TRANSACTIONS
            FROM 's3://favorita-retail-pipeline/raw/transactions.csv'
            CREDENTIALS = (
                AWS_KEY_ID= 'ASIAVX5O2PQE76MTG36M',
                AWS_SECRET_KEY= '***',
                AWS_TOKEN= '***'
            )
            FILE_FORMAT = (TYPE = 'CSV' FIELD_OPTIONALLY_ENCLOSED_BY = '"' SKIP_HEADER = 1);, parameters: None
[2025-08-07T00:09:13.198+0000] {connection.py:762} INFO - closed
[2025-08-07T00:09:13.261+0000] {connection.py:768} INFO - No async queries seem to be running, deleting session
[2025-08-07T00:09:13.326+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-08-07T00:09:13.328+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/operators/sql.py", line 282, in execute
    output = hook.run(
             ^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 395, in run
    self._run_command(cur, sql_statement, parameters)  # type: ignore[attr-defined]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/common/sql/hooks/sql.py", line 475, in _run_command
    cur.execute(sql_statement)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1080, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 345, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 091003 (22000): 01be32e9-0000-29a7-0000-003d698bc08d: Failure using stage area. Cause: [User: arn:aws:sts::394966760457:assumed-role/voclabs/user4052228=MBADRILA@depaul.edu is not authorized to perform: s3:ListBucket on resource: "arn:aws:s3:::favorita-retail-pipeline" with an explicit deny in an identity-based policy (Status Code: 403; Error Code: AccessDenied)]
[2025-08-07T00:09:13.340+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=s3_to_snowflake_loader, task_id=load_transactions_to_snowflake, run_id=manual__2025-08-07T00:09:07.574394+00:00, execution_date=20250807T000907, start_date=20250807T000912, end_date=20250807T000913
[2025-08-07T00:09:13.355+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 77 for task load_transactions_to_snowflake (091003 (22000): 01be32e9-0000-29a7-0000-003d698bc08d: Failure using stage area. Cause: [User: arn:aws:sts::394966760457:assumed-role/voclabs/user4052228=MBADRILA@depaul.edu is not authorized to perform: s3:ListBucket on resource: "arn:aws:s3:::favorita-retail-pipeline" with an explicit deny in an identity-based policy (Status Code: 403; Error Code: AccessDenied)]; 8034)
[2025-08-07T00:09:13.392+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2025-08-07T00:09:13.408+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
